<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Nomad Good, Kubernetes Bad | Andy Dote</title><meta name=keywords content="nomad,infrastructure,kubernetes"><meta name=description content="I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don&rsquo;t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator at all.
TLDR: I don&rsquo;t like complexity, and Kubernetes has more complexity than benefits.
Operational Complexity Operating Nomad is very straight forward. There are very few moving parts, so the number of things which can go wrong is significantly reduced."><meta name=author content><link rel=canonical href=https://andydote.co.uk/2019/11/21/nomad-good-kubernetes-bad/><link crossorigin=anonymous href=/assets/css/stylesheet.min.d3aaf8cdcec9a6487824ab95cadf08232ec362e7ba510c6b742973d16ef5b72e.css integrity="sha256-06r4zc7Jpkh4JKuVyt8IIy7DYue6UQxrdClz0W71ty4=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/mermaid.min.725f44bd345b0a2a4043ca952b0863edd789e913cf0813a12bbdfe986fe87079.js integrity="sha256-cl9EvTRbCipAQ8qVKwhj7deJ6RPPCBOhK73+mG/ocHk="></script>
<script defer crossorigin=anonymous src=/js/tabs.min.2d019e9ee3574770ad4ecfd4f5f794739892195cb82a4e6383252b9074ab520c.js integrity="sha256-LQGenuNXR3CtTs/U9feUc5iSGVy4Kk5jgyUrkHSrUgw="></script>
<link rel=icon href=https://andydote.co.uk/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://andydote.co.uk/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://andydote.co.uk/favicon-32x32.png><link rel=apple-touch-icon href=https://andydote.co.uk/apple-touch-icon.png><link rel=mask-icon href=https://andydote.co.uk/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Nomad Good, Kubernetes Bad"><meta property="og:description" content="I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don&rsquo;t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator at all.
TLDR: I don&rsquo;t like complexity, and Kubernetes has more complexity than benefits.
Operational Complexity Operating Nomad is very straight forward. There are very few moving parts, so the number of things which can go wrong is significantly reduced."><meta property="og:type" content="article"><meta property="og:url" content="https://andydote.co.uk/2019/11/21/nomad-good-kubernetes-bad/"><meta property="article:section" content="post"><meta property="article:published_time" content="2019-11-21T00:00:00+00:00"><meta property="article:modified_time" content="2019-11-21T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nomad Good, Kubernetes Bad"><meta name=twitter:description content="I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don&rsquo;t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator at all.
TLDR: I don&rsquo;t like complexity, and Kubernetes has more complexity than benefits.
Operational Complexity Operating Nomad is very straight forward. There are very few moving parts, so the number of things which can go wrong is significantly reduced."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://andydote.co.uk/post/"},{"@type":"ListItem","position":3,"name":"Nomad Good, Kubernetes Bad","item":"https://andydote.co.uk/2019/11/21/nomad-good-kubernetes-bad/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Nomad Good, Kubernetes Bad","name":"Nomad Good, Kubernetes Bad","description":"I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don\u0026rsquo;t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator at all.\nTLDR: I don\u0026rsquo;t like complexity, and Kubernetes has more complexity than benefits.\nOperational Complexity Operating Nomad is very straight forward. There are very few moving parts, so the number of things which can go wrong is significantly reduced.","keywords":["nomad","infrastructure","kubernetes"],"articleBody":"I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don’t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator at all.\nTLDR: I don’t like complexity, and Kubernetes has more complexity than benefits.\nOperational Complexity Operating Nomad is very straight forward. There are very few moving parts, so the number of things which can go wrong is significantly reduced. No external dependencies are required to run it, and there is only one binary to use. You run 3-5 copies in Server mode to manage the cluster and as many as you want running in Client mode to do the actual work. You can add Consul if you want service discovery, but it’s optional. More on that later.\nCompare this to operating a Kubernetes cluster. There are multiple Kubernetes orchestration projects, tools, and companies to get clusters up and running, which should be an indication of the level of complexity involved. Once you have the cluster set up, you need to keep it running. There are so many moving parts (Controller Manager, Scheduler, API Server, Etcd, Kubelets) that it quickly becomes a full-time job to keep the cluster up and running. Use a cloud service to run Kubernetes, and if you must use your own infrastructure, pay someone else to manage it. It’s cheaper in the long run. Trust me.\nDeployment Nomad, being a single binary, is easy to deploy. If you want to use Terraform to create a cluster, Hashicorp provides modules for both AWS and Azure. Alternatively, you can do everything yourself, as it’s just keeping one binary running on hosts, and a bit of network/DNS config to get them talking to each other.\nBy comparison, Kubernetes has a multitude of tools to help you deploy a cluster. Still, while it gives you a lot of flexibility in choice, you also have to hope that the tool continues to exist and that there is enough community/company/documentation about that specific tool to help you when something goes wrong.\nUpgrading The Cluster Upgrading Nomad involves doing a rolling deployment of the Servers and Clients. If you are using the Hashicorp Terraform module, you re-apply the module with the new AMI ID to use, and then delete nodes (gracefully!) from the cluster and let the AutoScaleGroup take care of bringing new nodes up. If you need to revert to an older version of Nomad, you follow the same process.\nWhen it comes to Kubernetes, please pay someone else to do it. It’s not a fun process. The process will differ depending on which cluster management tool you are using, and you also need to think about updates to etcd and managing state in the process. There is a nice long document on how to upgrade etcd.\nDebugging a Cluster As mentioned earlier, Nomad has a small number of moving parts. There are three ports involved (HTTP, RPC and Gossip), so as long as those ports are open and reachable, Nomad should be operable. Then you need to keep the Nomad agents alive. That’s pretty much it.\nWhere to start for Kubernetes? As many Kubernetes Failure Stories point out: it’s always DNS. Or etcd. Or Istio. Or networking. Or Kubelets. Or all of these.\nLocal Development To run Nomad locally, you use the same binary as the production clusters, but in dev mode: nomad agent -dev. To get a local cluster, you can spin up some Vagrant boxes instead. I use my Hashibox Vagrant box to do this when I do conference talks and don’t trust the wifi to work.\nTo run Kubernetes locally to test things, you need to install/deploy MiniKube, K3S, etc. The downside to this approach is that the environment is significantly different to your real Kubernetes cluster, and you can end up where a deployment works in one, but not the other, which makes debugging issues much harder.\nFeatures \u0026 Choice Nomad is relatively light on built-in features, which allows you the choice of what features to add, and what implementations of the features to use. For example, it is pretty popular to use Consul for service discovery, but if you would rather use Eureka, or Zookeeper, or even etcd, that is fine, but you lose out on the seamless integration with Nomad that other Hashicorp tools have. Nomad also supports Plugins if you want to add support for your favourite tool.\nBy comparison, Kubernetes does everything, but like the phrase “Jack of all trades, master of none”, often you will have to supplement the inbuilt features. The downside to this is that you can’t switch off Kubernetes features you are not using, or don’t want. So if you add Vault for secret management, the Kubernetes Secrets are still available, and you have to be careful that people don’t use them accidentally. The same goes for all other features, such as Load Balancing, Feature Toggles, Service Discovery, DNS, etc.\nSecret Management Nomad doesn’t provide a Secret Management solution out of the box, but it does have seamless Vault integration, and you are also free to use any other Secrets As A Service tool you like. If you do choose Vault, you can either use it directly from your tasks or use Nomad’s integration to provide the secrets to your application. It can even send a signal (e.g. SIGINT etc.) to your process when the secrets need re-reading.\nKubernetes, on the other hand, provides “Secrets”. I put the word “secrets” in quotes because they are not secrets at all. The values are stored encoded in base64 in etcd, so anyone who has access to the etcd cluster has access to all the secrets. The official documentation suggests making sure only administrators have access to the etcd cluster to solve this. Oh, and if you can deploy a container to the same namespace as a secret, you can reveal it by writing it to stdout.\nKubernetes secrets are not secret, just “slightly obscured.”\nIf you want real Secrets, you will almost certainly use Vault. You can either run it inside or outside of Kubernetes, and either use it directly from containers via it’s HTTPS API or use it to populate Kubernetes Secrets. I’d avoid populating Kubernetes Secrets if I were you.\nSupport If Nomad breaks, you can either use community support or if you are using the Enterprise version, you have Hashicorp’s support.\nWhen Kubernetes breaks, you can either use community support or find and buy support from a Kubernetes management company.\nThe main difference here is “when Kubernetes breaks” vs “if Nomad breaks”. The level of complexity in Kubernetes makes it far more likely to break, and that much harder to debug.\n","wordCount":"1128","inLanguage":"en","datePublished":"2019-11-21T00:00:00Z","dateModified":"2019-11-21T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://andydote.co.uk/2019/11/21/nomad-good-kubernetes-bad/"},"publisher":{"@type":"Organization","name":"Andy Dote","logo":{"@type":"ImageObject","url":"https://andydote.co.uk/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://andydote.co.uk accesskey=h title="Andy Dote (Alt + H)">Andy Dote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://andydote.co.uk/archive title=Archive><span>Archive</span></a></li><li><a href=https://andydote.co.uk/talks title=Talks><span>Talks</span></a></li><li><a href=https://andydote.co.uk/notes title=Notes><span>Notes</span></a></li><li><a href=https://andydote.co.uk/tags title=Tags><span>Tags</span></a></li><li><a href=https://andydote.co.uk/contact title=Contact><span>Contact</span></a></li><li><a href=https://andydote.co.uk/rss.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Nomad Good, Kubernetes Bad</h1><div class=post-meta><span title='2019-11-21 00:00:00 +0000 UTC'>November 21, 2019</span>&nbsp;·&nbsp;6 min</div></header><div class=post-content><p>I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don&rsquo;t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator <em>at all</em>.</p><p>TLDR: I don&rsquo;t like complexity, and Kubernetes has more complexity than benefits.</p><h3 id=operational-complexity>Operational Complexity<a hidden class=anchor aria-hidden=true href=#operational-complexity>#</a></h3><p>Operating Nomad is very straight forward. There are very few moving parts, so the number of things which can go wrong is significantly reduced. No external dependencies are required to run it, and there is only one binary to use. You run 3-5 copies in Server mode to manage the cluster and as many as you want running in Client mode to do the actual work. You can add Consul if you want service discovery, but it&rsquo;s optional. More on that later.</p><p>Compare this to operating a Kubernetes cluster. There are multiple Kubernetes orchestration projects, tools, and companies to get clusters up and running, which should be an indication of the level of complexity involved. Once you have the cluster set up, you need to keep it running. There are so many moving parts (Controller Manager, Scheduler, API Server, Etcd, Kubelets) that it quickly becomes a full-time job to keep the cluster up and running. Use a cloud service to run Kubernetes, and if you must use your own infrastructure, pay someone else to manage it. It&rsquo;s cheaper in the long run. Trust me.</p><h3 id=deployment>Deployment<a hidden class=anchor aria-hidden=true href=#deployment>#</a></h3><p>Nomad, being a single binary, is easy to deploy. If you want to use <a href=https://www.terraform.io/>Terraform</a> to create a cluster, Hashicorp provides modules for both <a href=https://github.com/hashicorp/terraform-aws-nomad>AWS</a> and <a href=https://github.com/hashicorp/terraform-azurerm-nomad>Azure</a>. Alternatively, you can do everything yourself, as it&rsquo;s just keeping one binary running on hosts, and a bit of network/DNS config to get them talking to each other.</p><p>By comparison, Kubernetes has a multitude of tools to help you deploy a cluster. Still, while it gives you a lot of flexibility in choice, you also have to hope that the tool continues to exist and that there is enough community/company/documentation about that specific tool to help you when something goes wrong.</p><h3 id=upgrading-the-cluster>Upgrading The Cluster<a hidden class=anchor aria-hidden=true href=#upgrading-the-cluster>#</a></h3><p>Upgrading Nomad involves doing a rolling deployment of the Servers and Clients. If you are using the Hashicorp Terraform module, you re-apply the module with the new AMI ID to use, and then delete nodes (gracefully!) from the cluster and let the AutoScaleGroup take care of bringing new nodes up. If you need to revert to an older version of Nomad, you follow the same process.</p><p>When it comes to Kubernetes, please pay someone else to do it. It&rsquo;s not a fun process. The process will differ depending on which cluster management tool you are using, and you also need to think about updates to etcd and managing state in the process. There is a <a href=https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/>nice long document</a> on how to upgrade etcd.</p><h3 id=debugging-a-cluster>Debugging a Cluster<a hidden class=anchor aria-hidden=true href=#debugging-a-cluster>#</a></h3><p>As mentioned earlier, Nomad has a small number of moving parts. There are three ports involved (HTTP, RPC and Gossip), so as long as those ports are open and reachable, Nomad should be operable. Then you need to keep the Nomad agents alive. That&rsquo;s pretty much it.</p><p>Where to start for Kubernetes? As many <a href=https://github.com/hjacobs/kubernetes-failure-stories>Kubernetes Failure Stories</a> point out: it&rsquo;s always DNS. Or etcd. Or Istio. Or networking. Or Kubelets. Or all of these.</p><h3 id=local-development>Local Development<a hidden class=anchor aria-hidden=true href=#local-development>#</a></h3><p>To run Nomad locally, you use the same binary as the production clusters, but in dev mode: <code>nomad agent -dev</code>. To get a local cluster, you can spin up some Vagrant boxes instead. I use my <a href=https://github.com/pondidum/hashibox>Hashibox</a> Vagrant box to do this when I do conference talks and don&rsquo;t trust the wifi to work.</p><p>To run Kubernetes locally to test things, you need to install/deploy MiniKube, K3S, etc. The downside to this approach is that the environment is significantly different to your real Kubernetes cluster, and you can end up where a deployment works in one, but not the other, which makes debugging issues much harder.</p><h3 id=features--choice>Features & Choice<a hidden class=anchor aria-hidden=true href=#features--choice>#</a></h3><p>Nomad is relatively light on built-in features, which allows you the choice of what features to add, and what implementations of the features to use. For example, it is pretty popular to use Consul for service discovery, but if you would rather use <a href=https://github.com/Netflix/eureka>Eureka</a>, or Zookeeper, or even etcd, that is fine, but you lose out on the seamless integration with Nomad that other Hashicorp tools have. Nomad also supports <a href=https://www.nomadproject.io/docs/internals/plugins/index.html>Plugins</a> if you want to add support for your favourite tool.</p><p>By comparison, Kubernetes does everything, but like the phrase &ldquo;Jack of all trades, master of none&rdquo;, often you will have to supplement the inbuilt features. The downside to this is that you can&rsquo;t switch off Kubernetes features you are not using, or don&rsquo;t want. So if you add Vault for secret management, the Kubernetes Secrets are still available, and you have to be careful that people don&rsquo;t use them accidentally. The same goes for all other features, such as Load Balancing, Feature Toggles, Service Discovery, DNS, etc.</p><h3 id=secret-management>Secret Management<a hidden class=anchor aria-hidden=true href=#secret-management>#</a></h3><p>Nomad doesn&rsquo;t provide a Secret Management solution out of the box, but it does have seamless Vault integration, and you are also free to use any other Secrets As A Service tool you like. If you do choose Vault, you can either use it directly from your tasks or use Nomad&rsquo;s integration to provide the secrets to your application. It can even send a signal (e.g. <code>SIGINT</code> etc.) to your process when the secrets need re-reading.</p><p>Kubernetes, on the other hand, provides &ldquo;Secrets&rdquo;. I put the word &ldquo;secrets&rdquo; in quotes because they are not secrets at all. The values are stored encoded in base64 in etcd, so anyone who has access to the etcd cluster has access to <em>all</em> the secrets. The <a href=https://kubernetes.io/docs/concepts/configuration/secret/#risks>official documentation</a> suggests making sure only administrators have access to the etcd cluster to solve this. Oh, and if you can deploy a container to the same namespace as a secret, you can reveal it by writing it to stdout.</p><blockquote><p>Kubernetes secrets are not secret, just &ldquo;slightly obscured.&rdquo;</p></blockquote><p>If you want real Secrets, you will almost certainly use Vault. You can either run it inside or outside of Kubernetes, and either use it directly from containers via it&rsquo;s HTTPS API or use it to populate Kubernetes Secrets. I&rsquo;d avoid populating Kubernetes Secrets if I were you.</p><h3 id=support>Support<a hidden class=anchor aria-hidden=true href=#support>#</a></h3><p>If Nomad breaks, you can either use community support or if you are using the Enterprise version, you have Hashicorp&rsquo;s support.</p><p>When Kubernetes breaks, you can either use community support or find and buy support from a Kubernetes management company.</p><p>The main difference here is &ldquo;when Kubernetes breaks&rdquo; vs &ldquo;if Nomad breaks&rdquo;. The level of complexity in Kubernetes makes it far more likely to break, and that much harder to debug.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://andydote.co.uk/tags/nomad/>nomad</a></li><li><a href=https://andydote.co.uk/tags/infrastructure/>infrastructure</a></li><li><a href=https://andydote.co.uk/tags/kubernetes/>kubernetes</a></li></ul><nav class=paginav><a class=prev href=https://andydote.co.uk/2019/12/22/libvirt-hostname-resolution/><span class=title>« Prev Page</span><br><span>Libvirt Hostname Resolution</span></a>
<a class=next href=https://andydote.co.uk/2019/10/06/vault-consul-bootstrap/><span class=title>Next Page »</span><br><span>Creating a Vault instance with a TLS Consul Cluster</span></a></nav></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>