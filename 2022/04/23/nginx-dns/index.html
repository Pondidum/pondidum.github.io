<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>An NGINX and DNS based outage | Andy Dote</title><meta name=keywords content="dns,nginx,aws"><meta name=description content="I recently encountered a behaviour in Nginx that I didn&rsquo;t expect and caused a production outage in the process. While I would love to blame DNS for this, as it&rsquo;s usually the cause of most network-related issues, in this case, the fault lies with Nginx.
I was running a very simple Nginx proxy, relaying an internal service to the outside world. The internal service is behind an AWS ALB, and the Nginx configuration was proxying to the ALB&rsquo;s FQDN:"><meta name=author content><link rel=canonical href=https://andydote.co.uk/2022/04/23/nginx-dns/><link crossorigin=anonymous href=/assets/css/stylesheet.min.b4e19c453811e60acfec1f00c15ac2be1c53f6ab90187e684358ce7faaf48bab.css integrity="sha256-tOGcRTgR5grP7B8AwVrCvhxT9quQGH5oQ1jOf6r0i6s=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.e85ad0406048e8176e1c7661b25d5c69297ddfe41dc4124cf75ecb99a4f7b3d1.js integrity="sha256-6FrQQGBI6BduHHZhsl1caSl93+QdxBJM917LmaT3s9E=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://andydote.co.uk/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://andydote.co.uk/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://andydote.co.uk/favicon-32x32.png><link rel=apple-touch-icon href=https://andydote.co.uk/apple-touch-icon.png><link rel=mask-icon href=https://andydote.co.uk/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="An NGINX and DNS based outage"><meta property="og:description" content="I recently encountered a behaviour in Nginx that I didn&rsquo;t expect and caused a production outage in the process. While I would love to blame DNS for this, as it&rsquo;s usually the cause of most network-related issues, in this case, the fault lies with Nginx.
I was running a very simple Nginx proxy, relaying an internal service to the outside world. The internal service is behind an AWS ALB, and the Nginx configuration was proxying to the ALB&rsquo;s FQDN:"><meta property="og:type" content="article"><meta property="og:url" content="https://andydote.co.uk/2022/04/23/nginx-dns/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-04-23T00:00:00+00:00"><meta property="article:modified_time" content="2022-04-23T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="An NGINX and DNS based outage"><meta name=twitter:description content="I recently encountered a behaviour in Nginx that I didn&rsquo;t expect and caused a production outage in the process. While I would love to blame DNS for this, as it&rsquo;s usually the cause of most network-related issues, in this case, the fault lies with Nginx.
I was running a very simple Nginx proxy, relaying an internal service to the outside world. The internal service is behind an AWS ALB, and the Nginx configuration was proxying to the ALB&rsquo;s FQDN:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://andydote.co.uk/post/"},{"@type":"ListItem","position":3,"name":"An NGINX and DNS based outage","item":"https://andydote.co.uk/2022/04/23/nginx-dns/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"An NGINX and DNS based outage","name":"An NGINX and DNS based outage","description":"I recently encountered a behaviour in Nginx that I didn\u0026rsquo;t expect and caused a production outage in the process. While I would love to blame DNS for this, as it\u0026rsquo;s usually the cause of most network-related issues, in this case, the fault lies with Nginx.\nI was running a very simple Nginx proxy, relaying an internal service to the outside world. The internal service is behind an AWS ALB, and the Nginx configuration was proxying to the ALB\u0026rsquo;s FQDN:","keywords":["dns","nginx","aws"],"articleBody":"I recently encountered a behaviour in Nginx that I didn’t expect and caused a production outage in the process. While I would love to blame DNS for this, as it’s usually the cause of most network-related issues, in this case, the fault lies with Nginx.\nI was running a very simple Nginx proxy, relaying an internal service to the outside world. The internal service is behind an AWS ALB, and the Nginx configuration was proxying to the ALB’s FQDN:\nhttp { server { listen 8000; server_name server.example.com; location ~* ^/some/path { proxy_pass https://some.internal.alb.address.amazonaws.com; proxy_set_header Host $host; proxy_read_timeout 120; proxy_ignore_headers Cache-Control; proxy_ignore_headers Expires; proxy_ignore_headers Set-Cookie; } } } The proxy was working fine for several weeks, until suddenly it wasn’t. To make matters more strange, when we checked the internal site directly, it showed as up and responding. No deployments of any services had happened, and we had made no changes in any infrastructure either. We restarted the Nginx service, and everything started working again.\nThe first is that AWS’s can, and does, change the IP addresses associated with load balancers. This can happen for many unknown reasons as the underlying implementation of the AWS load balancers is a black box. One known reason is the load balancer scaling to handle more or less traffic. There is no API that we are aware of that allows you to see when these changes have happened; the only way we know is to run dig in a loop and send the results to our observability tool when they change.\nThe second detail is how Nginx resolves DNS. My initial expectation was that it worked like most DNS clients, and would query an address on the first request and then again after the TTL had elapsed. It turns out my assumption was wrong, and that by default, Nginx queries addresses once on startup, and never again.\nSo with these two facts, we can see why the proxy stopped working at some point; the target ALB had removed whichever IP address(es) Nginx had received from DNS at startup. There are two different ways this can be fixed.\nThe first way is to force Nginx to cache all IPs resolved for a fixed time window:\nhttp { + resolver_timeout 30s; server { listen 8000; server_name server.example.com; location ~* ^/some/path { The second fix is to cause Nginx to re-resolve the upstream when it’s DNS record expires (based on the DNS TTL):\nhttp { server { listen 8000; server_name server.example.com; + set $upstream some.internal.alb.address.amazonaws.com; location ~* ^/some/path { - proxy_pass https://some.internal.alb.address.amazonaws.com; + proxy_pass https://$upstream; proxy_set_header Host $host; proxy_read_timeout 120; proxy_ignore_headers Cache-Control; proxy_ignore_headers Expires; proxy_ignore_headers Set-Cookie; } While I am glad there are two easy ways to solve this issue, I still find the default “only resolve once at startup” behaviour odd, as it goes against the Principle of least surprise; I expect Nginx to re-query based on the TTL of the DNS Record. I suspect this behaviour exists for performance reasons, but I don’t know for sure.\n","wordCount":"500","inLanguage":"en","datePublished":"2022-04-23T00:00:00Z","dateModified":"2022-04-23T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://andydote.co.uk/2022/04/23/nginx-dns/"},"publisher":{"@type":"Organization","name":"Andy Dote","logo":{"@type":"ImageObject","url":"https://andydote.co.uk/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://andydote.co.uk accesskey=h title="Andy Dote (Alt + H)">Andy Dote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://andydote.co.uk/archive title=Archive><span>Archive</span></a></li><li><a href=https://andydote.co.uk/talks title=Talks><span>Talks</span></a></li><li><a href=https://andydote.co.uk/notes title=Notes><span>Notes</span></a></li><li><a href=https://andydote.co.uk/tags title=Tags><span>Tags</span></a></li><li><a href=https://andydote.co.uk/contact title=Contact><span>Contact</span></a></li><li><a href=https://andydote.co.uk/rss.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>An NGINX and DNS based outage</h1><div class=post-meta><span title='2022-04-23 00:00:00 +0000 UTC'>April 23, 2022</span>&nbsp;·&nbsp;3 min</div></header><div class=post-content><p>I recently encountered a behaviour in Nginx that I didn&rsquo;t expect and caused a production outage in the process. While I would love to blame DNS for this, as it&rsquo;s usually the cause of most network-related issues, in this case, the fault lies with Nginx.</p><p>I was running a very simple Nginx proxy, relaying an internal service to the outside world. The internal service is behind an AWS ALB, and the Nginx configuration was proxying to the ALB&rsquo;s FQDN:</p><pre tabindex=0><code>http {
  server {
    listen              8000;
    server_name         server.example.com;

    location ~* ^/some/path {
      proxy_pass              https://some.internal.alb.address.amazonaws.com;
      proxy_set_header        Host $host;
      proxy_read_timeout      120;
      proxy_ignore_headers    Cache-Control;
      proxy_ignore_headers    Expires;
      proxy_ignore_headers    Set-Cookie;
    }
  }
}
</code></pre><p>The proxy was working fine for several weeks, until suddenly it wasn&rsquo;t. To make matters more strange, when we checked the internal site directly, it showed as up and responding. No deployments of any services had happened, and we had made no changes in any infrastructure either. We restarted the Nginx service, and everything started working again.</p><p>The first is that AWS&rsquo;s can, and does, change the IP addresses associated with load balancers. This can happen for many unknown reasons as the underlying implementation of the AWS load balancers is a black box. One known reason is the load balancer scaling to handle more or less traffic. There is no API that we are aware of that allows you to see when these changes have happened; the only way we know is to run <code>dig</code> in a loop and send the results to our observability tool when they change.</p><p>The second detail is how Nginx resolves DNS. My initial expectation was that it worked like most DNS clients, and would query an address on the first request and then again after the TTL had elapsed. It turns out my assumption was wrong, and that by default, Nginx queries addresses once on startup, <em>and never again</em>.</p><p>So with these two facts, we can see why the proxy stopped working at some point; the target ALB had removed whichever IP address(es) Nginx had received from DNS at startup. There are two different ways this can be fixed.</p><p>The first way is to force Nginx to cache all IPs resolved for a fixed time window:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>http {
</span></span><span style=display:flex><span><span style=color:#a6e22e>+  resolver_timeout 30s;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>
</span></span><span style=display:flex><span>  server {
</span></span><span style=display:flex><span>    listen              8000;
</span></span><span style=display:flex><span>    server_name         server.example.com;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    location ~* ^/some/path {
</span></span></code></pre></div><p>The second fix is to cause Nginx to re-resolve the upstream when it&rsquo;s DNS record expires (based on the DNS TTL):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>http {
</span></span><span style=display:flex><span>  server {
</span></span><span style=display:flex><span>    listen              8000;
</span></span><span style=display:flex><span>    server_name         server.example.com;
</span></span><span style=display:flex><span><span style=color:#a6e22e>+    set $upstream some.internal.alb.address.amazonaws.com;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>
</span></span><span style=display:flex><span>    location ~* ^/some/path {
</span></span><span style=display:flex><span><span style=color:#f92672>-     proxy_pass              https://some.internal.alb.address.amazonaws.com;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+     proxy_pass              https://$upstream;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>      proxy_set_header        Host $host;
</span></span><span style=display:flex><span>      proxy_read_timeout      120;
</span></span><span style=display:flex><span>      proxy_ignore_headers    Cache-Control;
</span></span><span style=display:flex><span>      proxy_ignore_headers    Expires;
</span></span><span style=display:flex><span>      proxy_ignore_headers    Set-Cookie;
</span></span><span style=display:flex><span>    }
</span></span></code></pre></div><p>While I am glad there are two easy ways to solve this issue, I still find the default &ldquo;only resolve once at startup&rdquo; behaviour odd, as it goes against the <a href=https://en.wikipedia.org/wiki/Principle_of_least_astonishment>Principle of least surprise</a>; I expect Nginx to re-query based on the TTL of the DNS Record. I suspect this behaviour exists for performance reasons, but I don&rsquo;t know for sure.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://andydote.co.uk/tags/dns/>dns</a></li><li><a href=https://andydote.co.uk/tags/nginx/>nginx</a></li><li><a href=https://andydote.co.uk/tags/aws/>aws</a></li></ul><nav class=paginav><a class=prev href=https://andydote.co.uk/2022/07/17/pulumi-faster-processes/><span class=title>« Prev Page</span><br><span>Pulumi Conditional Infrastructure for Speed</span></a>
<a class=next href=https://andydote.co.uk/2021/11/22/nomad-operator-pattern/><span class=title>Next Page »</span><br><span>The Operator Pattern in Nomad</span></a></nav></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>