<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Testing RabbitMQ Concurrency in MassTransit | Andy Dote</title><meta name=keywords content="masstransit,rabbitmq,testing"><meta name=description content="We have a service which consumes messages from a RabbitMQ queue - for each message, it makes a few http calls, collates the results, does a little processing, and then pushes the results to a 3rd party api. One of the main benefits to having this behind a queue is our usage pattern - the queue usually only has a few messages in it per second, but periodically it will get a million or so messages within 30 minutes (so from ~5 messages/second to ~560 messages/second."><meta name=author content><link rel=canonical href=https://andydote.co.uk/2017/10/11/masstransit-rabbitmq-concurrency-testing/><link crossorigin=anonymous href=/assets/css/stylesheet.min.4ac25d88867f6882d86478d9b478a3d3efa1ed9e18f0bc5e432812301516cb28.css integrity="sha256-SsJdiIZ/aILYZHjZtHij0++h7Z4Y8LxeQygSMBUWyyg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/mermaid.min.725f44bd345b0a2a4043ca952b0863edd789e913cf0813a12bbdfe986fe87079.js integrity="sha256-cl9EvTRbCipAQ8qVKwhj7deJ6RPPCBOhK73+mG/ocHk="></script>
<script defer crossorigin=anonymous src=/js/tabs.min.2d019e9ee3574770ad4ecfd4f5f794739892195cb82a4e6383252b9074ab520c.js integrity="sha256-LQGenuNXR3CtTs/U9feUc5iSGVy4Kk5jgyUrkHSrUgw="></script>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://andydote.co.uk/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://andydote.co.uk/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://andydote.co.uk/favicon-32x32.png><link rel=apple-touch-icon href=https://andydote.co.uk/apple-touch-icon.png><link rel=mask-icon href=https://andydote.co.uk/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Testing RabbitMQ Concurrency in MassTransit"><meta property="og:description" content="We have a service which consumes messages from a RabbitMQ queue - for each message, it makes a few http calls, collates the results, does a little processing, and then pushes the results to a 3rd party api. One of the main benefits to having this behind a queue is our usage pattern - the queue usually only has a few messages in it per second, but periodically it will get a million or so messages within 30 minutes (so from ~5 messages/second to ~560 messages/second."><meta property="og:type" content="article"><meta property="og:url" content="https://andydote.co.uk/2017/10/11/masstransit-rabbitmq-concurrency-testing/"><meta property="article:section" content="post"><meta property="article:published_time" content="2017-10-11T00:00:00+00:00"><meta property="article:modified_time" content="2017-10-11T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Testing RabbitMQ Concurrency in MassTransit"><meta name=twitter:description content="We have a service which consumes messages from a RabbitMQ queue - for each message, it makes a few http calls, collates the results, does a little processing, and then pushes the results to a 3rd party api. One of the main benefits to having this behind a queue is our usage pattern - the queue usually only has a few messages in it per second, but periodically it will get a million or so messages within 30 minutes (so from ~5 messages/second to ~560 messages/second."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://andydote.co.uk/post/"},{"@type":"ListItem","position":3,"name":"Testing RabbitMQ Concurrency in MassTransit","item":"https://andydote.co.uk/2017/10/11/masstransit-rabbitmq-concurrency-testing/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Testing RabbitMQ Concurrency in MassTransit","name":"Testing RabbitMQ Concurrency in MassTransit","description":"We have a service which consumes messages from a RabbitMQ queue - for each message, it makes a few http calls, collates the results, does a little processing, and then pushes the results to a 3rd party api. One of the main benefits to having this behind a queue is our usage pattern - the queue usually only has a few messages in it per second, but periodically it will get a million or so messages within 30 minutes (so from ~5 messages/second to ~560 messages/second.","keywords":["masstransit","rabbitmq","testing"],"articleBody":"We have a service which consumes messages from a RabbitMQ queue - for each message, it makes a few http calls, collates the results, does a little processing, and then pushes the results to a 3rd party api. One of the main benefits to having this behind a queue is our usage pattern - the queue usually only has a few messages in it per second, but periodically it will get a million or so messages within 30 minutes (so from ~5 messages/second to ~560 messages/second.)\nProcessing this spike of messages takes ages, and while this service is only on a T2.Medium machine (2 CPUs, 4GB Memory), it only uses 5-10% CPU while processing the messages, which is clearly pretty inefficient.\nWe use MassTransit when interacting with RabbitMQ as it provides us with a lot of useful features, but by default sets the amount of messages to be processed in parallel to Environment.ProcessorCount * 2. For this project that means 4 messages, and as the process is IO bound, it stands to reason that we could increase that concurrency a bit. Or a lot.\nThe existing MassTransit setup looks pretty similar to this:\n_bus = Bus.Factory.CreateUsingRabbitMq(rabbit =\u003e { var host = rabbit.Host(new Uri(\"rabbitmq://localhost\"), h =\u003e { h.Username(\"guest\"); h.Password(\"guest\"); }); rabbit.ReceiveEndpoint(host, \"SpikyQueue\", endpoint =\u003e { endpoint.Consumer(() =\u003e new TestConsumer()); }); }); The Test (Driven Development) As we like testing things, I wrote a test to validate the degree of concurrency we have. We use a real instance of RabbitMQ (Started with Docker, as part of the build), and have a test message and consumer. Due to the speed of RabbitMQ delivery, we make the consumer just take a little bit of time before returning:\nclass TestMessage { public int Value { get; set; } } class TestConsumer : IConsumer { public async Task Consume(ConsumeContext context) { await Task.Delay(600); } } The final piece of our puzzle is an IConsumeObserver, which will count the number of messages processed in parallel, as well as the total number of messages processed. We will use the total number of messages to know when our test can stop running, and the parallel number to prove if our concurrency changes worked.\nWhat this observer is doing is the following, but as we are in a multithreaded environment, we need to use the Interlocked class, and do a bit more work to make sure we don’t lose values:\nPreConsume: currentPendingDeliveryCount++ maxPendingDeliveryCount = Math.Max(maxPendingDeliveryCount, currentPendingDeliveryCount) PostConsume: currentPendingDeliveryCount-- The actual ConsumeCountObserver code is as follows:\nclass ConsumeCountObserver : IConsumeObserver { int _deliveryCount; int _currentPendingDeliveryCount; int _maxPendingDeliveryCount; readonly int _messageCount; readonly TaskCompletionSource\u003cbool\u003e _complete; public ConsumeCountObserver(int messageCount) { _messageCount = messageCount; _complete = new TaskCompletionSource\u003cbool\u003e(); } public int MaxDeliveryCount =\u003e _maxPendingDeliveryCount; public async Task Wait() =\u003e await _complete.Task; Task IConsumeObserver.ConsumeFault(ConsumeContext context, Exception exception) =\u003e Task.CompletedTask; Task IConsumeObserver.PreConsume(ConsumeContext context) { Interlocked.Increment(ref _deliveryCount); var current = Interlocked.Increment(ref _currentPendingDeliveryCount); while (current \u003e _maxPendingDeliveryCount) Interlocked.CompareExchange(ref _maxPendingDeliveryCount, current, _maxPendingDeliveryCount); return Task.CompletedTask; } Task IConsumeObserver.PostConsume(ConsumeContext context) { Interlocked.Decrement(ref _currentPendingDeliveryCount); if (_deliveryCount == _messageCount) _complete.TrySetResult(true); return Task.CompletedTask; } } Finally, we can put the actual test together: We publish some messages, connect the observer, and start processing. Finally, when the observer indicates we have finished, we assert that the MaxDeliveryCount was the same as the ConcurrencyLimit:\n[Test] public async Task WhenTestingSomething() { for (var i = 0; i \u003c MessageCount; i++) await _bus.Publish(new TestMessage { Value = i }); var observer = new ConsumeCountObserver(MessageCount); _bus.ConnectConsumeObserver(observer); await _bus.StartAsync(); await observer.Wait(); await _bus.StopAsync(); observer.MaxDeliveryCount.ShouldBe(ConcurrencyLimit); } The Problem The problem we had was actually increasing the concurrency: There are two things you can change, .UseConcurrencyLimit(32) and .PrefetchCount = 32, but doing this doesn’t work:\n_bus = Bus.Factory.CreateUsingRabbitMq(rabbit =\u003e { var host = rabbit.Host(new Uri(\"rabbitmq://localhost\"), h =\u003e { h.Username(\"guest\"); h.Password(\"guest\"); }); rabbit.ReceiveEndpoint(host, \"SpikeyQueue\", endpoint =\u003e { endpoint.UseConcurrencyLimit(ConcurrencyLimit); endpoint.PrefetchCount = (ushort) ConcurrencyLimit; endpoint.Consumer(() =\u003e new TestConsumer()); }); }); Or well…it does work, if the ConcurrencyLimit is less than the default. After a lot of trial and error, it turns out there are not two things you can change, but four:\nrabbit.UseConcurrencyLimit(val) rabbit.PrefetchCount = val endpoint.UseConcurrencyLimit(val) endpoint.PrefetchCount = val This makes sense (kind of): You can set limits on the factory, and then the endpoints can be any value less than or equal to the factory limits. My process of trial and error to work out which needed to be set:\nSet them all to 32 Run test if it passes, remove one setting, go to 2. if it fails, add last setting back, remove a different setting, go to 2. After iterating this set of steps for a while, it turns out for my use case that I need to set rabbit.UseConcurrencyLimit(val) and endpoint.PrefetchCount = val:\n_bus = Bus.Factory.CreateUsingRabbitMq(rabbit =\u003e { var host = rabbit.Host(new Uri(\"rabbitmq://localhost\"), h =\u003e { h.Username(\"guest\"); h.Password(\"guest\"); }); rabbit.UseConcurrencyLimit(ConcurrencyLimit); rabbit.ReceiveEndpoint(host, \"SpikeyQueue\", endpoint =\u003e { endpoint.PrefetchCount = (ushort) ConcurrencyLimit; endpoint.Consumer(() =\u003e new TestConsumer()); }); }); Interestingly, no matter which place you set the PrefetchCount value, it doesn’t show up in the RabbitMQ web dashboard.\nHope this might help someone else struggling with getting higher concurrency with MassTransit.\n","wordCount":"836","inLanguage":"en","datePublished":"2017-10-11T00:00:00Z","dateModified":"2017-10-11T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://andydote.co.uk/2017/10/11/masstransit-rabbitmq-concurrency-testing/"},"publisher":{"@type":"Organization","name":"Andy Dote","logo":{"@type":"ImageObject","url":"https://andydote.co.uk/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://andydote.co.uk accesskey=h title="Andy Dote (Alt + H)">Andy Dote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://andydote.co.uk/archive title=Archive><span>Archive</span></a></li><li><a href=https://andydote.co.uk/talks title=Talks><span>Talks</span></a></li><li><a href=https://andydote.co.uk/notes title=Notes><span>Notes</span></a></li><li><a href=https://andydote.co.uk/tags title=Tags><span>Tags</span></a></li><li><a href=https://andydote.co.uk/contact title=Contact><span>Contact</span></a></li><li><a href=https://andydote.co.uk/rss.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Testing RabbitMQ Concurrency in MassTransit</h1><div class=post-meta><span title='2017-10-11 00:00:00 +0000 UTC'>October 11, 2017</span>&nbsp;·&nbsp;4 min</div></header><div class=post-content><p>We have a service which consumes messages from a <a href=http://www.rabbitmq.com/>RabbitMQ</a> queue - for each message, it makes a few http calls, collates the results, does a little processing, and then pushes the results to a 3rd party api. One of the main benefits to having this behind a queue is our usage pattern - the queue usually only has a few messages in it per second, but periodically it will get a million or so messages within 30 minutes (so from ~5 messages/second to ~560 messages/second.)</p><p>Processing this spike of messages takes ages, and while this service is only on a <code>T2.Medium</code> machine (2 CPUs, 4GB Memory), it only uses 5-10% CPU while processing the messages, which is clearly pretty inefficient.</p><p>We use <a href=http://masstransit-project.com/>MassTransit</a> when interacting with RabbitMQ as it provides us with a lot of useful features, but by default sets the amount of messages to be processed in parallel to <code>Environment.ProcessorCount * 2</code>. For this project that means 4 messages, and as the process is IO bound, it stands to reason that we could increase that concurrency a bit. Or a lot.</p><p>The existing MassTransit setup looks pretty similar to this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span>_bus = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> host = rabbit.Host(<span style=color:#66d9ef>new</span> Uri(<span style=color:#e6db74>&#34;rabbitmq://localhost&#34;</span>), h =&gt;
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        h.Username(<span style=color:#e6db74>&#34;guest&#34;</span>);
</span></span><span style=display:flex><span>        h.Password(<span style=color:#e6db74>&#34;guest&#34;</span>);
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    rabbit.ReceiveEndpoint(host, <span style=color:#e6db74>&#34;SpikyQueue&#34;</span>, endpoint =&gt;
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        endpoint.Consumer(() =&gt; <span style=color:#66d9ef>new</span> TestConsumer());
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><h2 id=the-test-driven-development>The Test (Driven Development)<a hidden class=anchor aria-hidden=true href=#the-test-driven-development>#</a></h2><p>As we like testing things, I wrote a test to validate the degree of concurrency we have. We use a real instance of RabbitMQ (<a href=/2017/10/02/dotnet-core-docker-integration-tests/>Started with Docker, as part of the build</a>), and have a test message and consumer. Due to the speed of RabbitMQ delivery, we make the consumer just take a little bit of time before returning:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>TestMessage</span>
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>int</span> Value { <span style=color:#66d9ef>get</span>; <span style=color:#66d9ef>set</span>; }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>TestConsumer</span> : IConsumer&lt;TestMessage&gt;
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>async</span> Task Consume(ConsumeContext&lt;TestMessage&gt; context)
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> Task.Delay(<span style=color:#ae81ff>600</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The final piece of our puzzle is an <code>IConsumeObserver</code>, which will count the number of messages processed in parallel, as well as the total number of messages processed. We will use the total number of messages to know when our test can stop running, and the parallel number to prove if our concurrency changes worked.</p><p>What this observer is doing is the following, but as we are in a multithreaded environment, we need to use the <code>Interlocked</code> class, and do a bit more work to make sure we don&rsquo;t lose values:</p><pre tabindex=0><code>PreConsume:
    currentPendingDeliveryCount++
    maxPendingDeliveryCount = Math.Max(maxPendingDeliveryCount, currentPendingDeliveryCount)
PostConsume:
    currentPendingDeliveryCount--
</code></pre><p>The actual <code>ConsumeCountObserver</code> code is as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ConsumeCountObserver</span> : IConsumeObserver
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> _deliveryCount;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> _currentPendingDeliveryCount;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> _maxPendingDeliveryCount;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>readonly</span> <span style=color:#66d9ef>int</span> _messageCount;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>readonly</span> TaskCompletionSource&lt;<span style=color:#66d9ef>bool</span>&gt; _complete;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> ConsumeCountObserver(<span style=color:#66d9ef>int</span> messageCount)
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        _messageCount = messageCount;
</span></span><span style=display:flex><span>        _complete = <span style=color:#66d9ef>new</span> TaskCompletionSource&lt;<span style=color:#66d9ef>bool</span>&gt;();
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>int</span> MaxDeliveryCount =&gt; _maxPendingDeliveryCount;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>async</span> Task Wait() =&gt; <span style=color:#66d9ef>await</span> _complete.Task;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Task IConsumeObserver.ConsumeFault&lt;T&gt;(ConsumeContext&lt;T&gt; context, Exception exception) =&gt; Task.CompletedTask;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Task IConsumeObserver.PreConsume&lt;T&gt;(ConsumeContext&lt;T&gt; context)
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        Interlocked.Increment(<span style=color:#66d9ef>ref</span> _deliveryCount);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> current = Interlocked.Increment(<span style=color:#66d9ef>ref</span> _currentPendingDeliveryCount);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> (current &gt; _maxPendingDeliveryCount)
</span></span><span style=display:flex><span>            Interlocked.CompareExchange(<span style=color:#66d9ef>ref</span> _maxPendingDeliveryCount, current, _maxPendingDeliveryCount);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> Task.CompletedTask;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Task IConsumeObserver.PostConsume&lt;T&gt;(ConsumeContext&lt;T&gt; context)
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        Interlocked.Decrement(<span style=color:#66d9ef>ref</span> _currentPendingDeliveryCount);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> (_deliveryCount == _messageCount)
</span></span><span style=display:flex><span>            _complete.TrySetResult(<span style=color:#66d9ef>true</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> Task.CompletedTask;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Finally, we can put the actual test together: We publish some messages, connect the observer, and start processing. Finally, when the observer indicates we have finished, we assert that the <code>MaxDeliveryCount</code> was the same as the <code>ConcurrencyLimit</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span><span style=color:#a6e22e>[Test]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>public</span> <span style=color:#66d9ef>async</span> Task WhenTestingSomething()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>var</span> i = <span style=color:#ae81ff>0</span>; i &lt; MessageCount; i++)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> _bus.Publish(<span style=color:#66d9ef>new</span> TestMessage { Value = i });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> observer = <span style=color:#66d9ef>new</span> ConsumeCountObserver(MessageCount);
</span></span><span style=display:flex><span>    _bus.ConnectConsumeObserver(observer);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> _bus.StartAsync();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> observer.Wait();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> _bus.StopAsync();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    observer.MaxDeliveryCount.ShouldBe(ConcurrencyLimit);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=the-problem>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem>#</a></h2><p>The problem we had was actually increasing the concurrency: There are two things you can change, <code>.UseConcurrencyLimit(32)</code> and <code>.PrefetchCount = 32</code>, but doing this doesn&rsquo;t work:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span>_bus = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> host = rabbit.Host(<span style=color:#66d9ef>new</span> Uri(<span style=color:#e6db74>&#34;rabbitmq://localhost&#34;</span>), h =&gt;
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        h.Username(<span style=color:#e6db74>&#34;guest&#34;</span>);
</span></span><span style=display:flex><span>        h.Password(<span style=color:#e6db74>&#34;guest&#34;</span>);
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    rabbit.ReceiveEndpoint(host, <span style=color:#e6db74>&#34;SpikeyQueue&#34;</span>, endpoint =&gt;
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        endpoint.UseConcurrencyLimit(ConcurrencyLimit);
</span></span><span style=display:flex><span>        endpoint.PrefetchCount = (<span style=color:#66d9ef>ushort</span>) ConcurrencyLimit;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        endpoint.Consumer(() =&gt; <span style=color:#66d9ef>new</span> TestConsumer());
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><p>Or well&mldr;it does work, if the <code>ConcurrencyLimit</code> is <strong>less</strong> than the default. After a lot of trial and error, it turns out there are not two things you can change, but four:</p><ul><li><code>rabbit.UseConcurrencyLimit(val)</code></li><li><code>rabbit.PrefetchCount = val</code></li><li><code>endpoint.UseConcurrencyLimit(val)</code></li><li><code>endpoint.PrefetchCount = val</code></li></ul><p>This makes sense (kind of): You can set limits on the factory, and then the endpoints can be any value less than or equal to the factory limits. My process of trial and error to work out which needed to be set:</p><ol><li>Set them all to 32</li><li>Run test<ul><li>if it passes, remove one setting, go to 2.</li><li>if it fails, add last setting back, remove a different setting, go to 2.</li></ul></li></ol><p>After iterating this set of steps for a while, it turns out for my use case that I need to set <code>rabbit.UseConcurrencyLimit(val)</code> and <code>endpoint.PrefetchCount = val</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span>_bus = Bus.Factory.CreateUsingRabbitMq(rabbit =&gt;
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> host = rabbit.Host(<span style=color:#66d9ef>new</span> Uri(<span style=color:#e6db74>&#34;rabbitmq://localhost&#34;</span>), h =&gt;
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        h.Username(<span style=color:#e6db74>&#34;guest&#34;</span>);
</span></span><span style=display:flex><span>        h.Password(<span style=color:#e6db74>&#34;guest&#34;</span>);
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    rabbit.UseConcurrencyLimit(ConcurrencyLimit);
</span></span><span style=display:flex><span>    rabbit.ReceiveEndpoint(host, <span style=color:#e6db74>&#34;SpikeyQueue&#34;</span>, endpoint =&gt;
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        endpoint.PrefetchCount = (<span style=color:#66d9ef>ushort</span>) ConcurrencyLimit;
</span></span><span style=display:flex><span>        endpoint.Consumer(() =&gt; <span style=color:#66d9ef>new</span> TestConsumer());
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><p>Interestingly, no matter which place you set the <code>PrefetchCount</code> value, it doesn&rsquo;t show up in the RabbitMQ web dashboard.</p><p>Hope this might help someone else struggling with getting higher concurrency with MassTransit.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://andydote.co.uk/tags/masstransit/>masstransit</a></li><li><a href=https://andydote.co.uk/tags/rabbitmq/>rabbitmq</a></li><li><a href=https://andydote.co.uk/tags/testing/>testing</a></li></ul><nav class=paginav><a class=prev href=https://andydote.co.uk/2017/10/22/vagrant-in-a-world-of-docker/><span class=title>« Prev Page</span><br><span>Vagrant in the world of Docker</span></a>
<a class=next href=https://andydote.co.uk/2017/10/04/structuremap-composite-decorator/><span class=title>Next Page »</span><br><span>Composite Decorators with StructureMap</span></a></nav></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>