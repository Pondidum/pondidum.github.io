<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>nomad on Andy Dote</title><link>https://andydote.co.uk/tags/nomad/</link><description>Recent content in nomad on Andy Dote</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Mon, 22 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://andydote.co.uk/tags/nomad/rss.xml" rel="self" type="application/rss+xml"/><item><title>The Operator Pattern in Nomad</title><link>https://andydote.co.uk/2021/11/22/nomad-operator-pattern/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://andydote.co.uk/2021/11/22/nomad-operator-pattern/</guid><description>The Operator Pattern from Kubernetes is an excellent way of handling tasks in a cluster in an automated way, for example, provisioning applications, running backups, requesting certificates, and injecting chaos testing.
As a Nomad user, I wanted to do something similar for my clusters, so I set about seeing how it would be possible. It turns out; it is much easier than I expected! While Nomad doesn&amp;rsquo;t support the idea of Custom Resource Definitions, we can achieve an operator by utilising a regular Nomad job and the nomad HTTP API.</description><content:encoded><![CDATA[<p>The <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">Operator Pattern</a> from Kubernetes is an excellent way of handling tasks in a cluster in an automated way, for example, provisioning applications, running backups, requesting certificates, and injecting chaos testing.</p>
<p>As a Nomad user, I wanted to do something similar for my clusters, so I set about seeing how it would be possible.  It turns out; it is much easier than I expected!  While Nomad doesn&rsquo;t support the idea of Custom Resource Definitions, we can achieve an operator by utilising a regular Nomad job and the nomad HTTP API.</p>
<h2 id="the-setup">The Setup</h2>
<p>We&rsquo;re going to build an automated backup operator!  We&rsquo;ll use the  <a href="https://www.nomadproject.io/api-docs/events">Nomad Streaming API</a> to watch for jobs being registered and deregistered.  If a job has some metadata for auto backup, we&rsquo;ll create (or update) a backup job.  If a job is deregistered or doesn&rsquo;t have any auto backup metadata, we&rsquo;ll try to delete a backup job if it exists.</p>
<p>The complete source code is available in the <a href="https://github.com/Pondidum/nomad-operator">Nomad-Operator</a> repo on my GitHub.</p>
<h2 id="consuming-the-nomad-streaming-api">Consuming the Nomad Streaming API</h2>
<p>The <a href="https://pkg.go.dev/github.com/hashicorp/nomad/api">Nomad Go API library</a> makes it easy to consume the streaming API, handling all the details, such as deserialisation for us.</p>
<p>The client is created with no additional parameters, as the <code>Address</code> and <code>SecretID</code> will be populated from environment variables automatically (<code>NOMAD_ADDR</code> and <code>NOMAD_TOKEN</code> respectively):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#a6e22e">client</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">NewClient</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">Config</span>{})
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">err</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As we want to only listen to jobs that have been modified after our application deploys, we need to query what the current job index is at startup:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">var</span> <span style="color:#a6e22e">index</span> <span style="color:#66d9ef">uint64</span> = <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">meta</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">client</span>.<span style="color:#a6e22e">Jobs</span>().<span style="color:#a6e22e">List</span>(<span style="color:#66d9ef">nil</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">==</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">index</span> = <span style="color:#a6e22e">meta</span>.<span style="color:#a6e22e">LastIndex</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Next, we use the <code>EventStream</code> API and subscribe to all job event types (in practice, this means <code>JobRegistered</code>, <code>JobDeregistered</code>, and <code>JobBatchDeregistered</code>):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#a6e22e">topics</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">map</span>[<span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">Topic</span>][]<span style="color:#66d9ef">string</span>{
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">TopicJob</span>: {<span style="color:#e6db74">&#34;*&#34;</span>},
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">eventsClient</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">client</span>.<span style="color:#a6e22e">EventStream</span>()
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">eventCh</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">eventsClient</span>.<span style="color:#a6e22e">Stream</span>(<span style="color:#a6e22e">ctx</span>, <span style="color:#a6e22e">topics</span>, <span style="color:#a6e22e">index</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">QueryOptions</span>{})
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">err</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>Stream(...)</code> call itself returns a channel which we can loop over forever consuming events, ignoring the heartbeat events:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">select</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">case</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">ctx</span>.<span style="color:#a6e22e">Done</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">case</span> <span style="color:#a6e22e">event</span> <span style="color:#f92672">:=</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">eventCh</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">event</span>.<span style="color:#a6e22e">IsHeartbeat</span>() {
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">c</span>.<span style="color:#a6e22e">handleEvent</span>(<span style="color:#a6e22e">event</span>)
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Finally, this operator only cares about jobs being registered and deregistered, so we loop through all the events and only handle the <code>JobRegistered</code> and <code>JobDeregistered</code> events:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">e</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">event</span>.<span style="color:#a6e22e">Events</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">e</span>.<span style="color:#a6e22e">Type</span> <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#34;JobRegistered&#34;</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#a6e22e">e</span>.<span style="color:#a6e22e">Type</span> <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#34;JobDeregistered&#34;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">job</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">e</span>.<span style="color:#a6e22e">Job</span>()
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">c</span>.<span style="color:#a6e22e">onJob</span>(<span style="color:#a6e22e">e</span>.<span style="color:#a6e22e">Type</span>, <span style="color:#a6e22e">job</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="handling-jobs">Handling Jobs</h2>
<p>When we see jobs, we need to handle a few different cases:</p>
<ul>
<li>Jobs which are backup jobs themselves should be ignored</li>
<li>Jobs without backup settings should have their backup job removed (if it exists)</li>
<li>Jobs with backup settings should have their job created (or updated if it exists)</li>
<li>Deregistered jobs should have their backup job removed (if it exists)</li>
</ul>
<p>We&rsquo;re using the job level <code>meta</code> stanza in the <code>.nomad</code> files for our settings, which looks something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-hcl" data-lang="hcl"><span style="display:flex;"><span><span style="color:#66d9ef">task</span> <span style="color:#e6db74">&#34;server&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">meta</span> {
</span></span><span style="display:flex;"><span>    auto-backup <span style="color:#f92672">=</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    backup-schedule <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;@daily&#34;</span>
</span></span><span style="display:flex;"><span>    backup-target-db <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;postgres&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">Backup</span>) <span style="color:#a6e22e">OnJob</span>(<span style="color:#a6e22e">eventType</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">job</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">Job</span>) {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">HasPrefix</span>(<span style="color:#f92672">*</span><span style="color:#a6e22e">job</span>.<span style="color:#a6e22e">ID</span>, <span style="color:#e6db74">&#34;backup-&#34;</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">backupID</span> <span style="color:#f92672">:=</span> <span style="color:#e6db74">&#34;backup-&#34;</span> <span style="color:#f92672">+</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">job</span>.<span style="color:#a6e22e">ID</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">settings</span>, <span style="color:#a6e22e">enabled</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">parseMeta</span>(<span style="color:#a6e22e">job</span>.<span style="color:#a6e22e">Meta</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">eventType</span> <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;JobDeregistered&#34;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">tryRemoveBackupJob</span>(<span style="color:#a6e22e">backupID</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> !<span style="color:#a6e22e">enabled</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">tryRemoveBackupJob</span>(<span style="color:#a6e22e">backupID</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">createBackupJob</span>(<span style="color:#a6e22e">backupID</span>, <span style="color:#a6e22e">settings</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Attempting to remove the job is straightforward as we don&rsquo;t care if it fails - it could be that the job doesn&rsquo;t exist, or is already stopped, or any other number of reasons, so we can use the <code>Deregister()</code> call and discard the output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">Backup</span>) <span style="color:#a6e22e">tryRemoveBackupJob</span>(<span style="color:#a6e22e">jobID</span> <span style="color:#66d9ef">string</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">client</span>.<span style="color:#a6e22e">Jobs</span>().<span style="color:#a6e22e">Deregister</span>(<span style="color:#a6e22e">jobID</span>, <span style="color:#66d9ef">false</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">WriteOptions</span>{})
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Creating the backup job involves rendering a go template of the nomad file we will use, and then calling <code>Register</code> to submit the job to Nomad.  We&rsquo;re using the fact that our backup IDs are stable, so re-running the same backup ID will replace the job with a new version.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">Backup</span>) <span style="color:#a6e22e">createBackupJob</span>(<span style="color:#a6e22e">id</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">s</span> <span style="color:#a6e22e">settings</span>) <span style="color:#66d9ef">error</span> {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">t</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">template</span>.<span style="color:#a6e22e">New</span>(<span style="color:#e6db74">&#34;&#34;</span>).<span style="color:#a6e22e">Delims</span>(<span style="color:#e6db74">&#34;[[&#34;</span>, <span style="color:#e6db74">&#34;]]&#34;</span>).<span style="color:#a6e22e">Parse</span>(<span style="color:#a6e22e">backupHcl</span>)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">err</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">var</span> <span style="color:#a6e22e">buffer</span> <span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">Buffer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Execute</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">buffer</span>, <span style="color:#a6e22e">s</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">err</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">backup</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">jobspec</span>.<span style="color:#a6e22e">Parse</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">buffer</span>)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">err</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">client</span>.<span style="color:#a6e22e">Jobs</span>().<span style="color:#a6e22e">Register</span>(<span style="color:#a6e22e">backup</span>, <span style="color:#66d9ef">nil</span>)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">err</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The nomad file is embedded using the Go <a href="https://pkg.go.dev/embed">embed</a> package to store the <code>.nomad</code> file in the binary, so we still have a single artefact to deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#75715e">//go:embed backup.nomad
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">var</span> <span style="color:#a6e22e">backupHcl</span> <span style="color:#66d9ef">string</span>
</span></span></code></pre></div><p>And the <code>backup.nomad</code> file itself is a go template with custom delimiters (<code>[[</code> and <code>]]</code>) for fields, as the <code>.nomad</code> file, can contain <code>{{ }}</code> when using the inbuilt templating for populating secrets, amongst other things:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>job <span style="color:#e6db74">&#34;[[ .JobID ]]&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  datacenters <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;dc1&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;batch&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  periodic <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    cron             <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;[[ .Schedule ]]&#34;</span>
</span></span><span style="display:flex;"><span>    prohibit_overlap <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  group <span style="color:#e6db74">&#34;backup&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    task <span style="color:#e6db74">&#34;backup&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      config <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        image   <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;alpine:latest&#34;</span>
</span></span><span style="display:flex;"><span>        command <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;echo&#34;</span>
</span></span><span style="display:flex;"><span>        args    <span style="color:#f92672">=</span> <span style="color:#f92672">[</span> <span style="color:#e6db74">&#34;backing up [[ .SourceJobID ]]&#39;s [[ .TargetDB ]] database&#34;</span> <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      env <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        PGHOST     <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;postgres.service.consul&#34;</span>
</span></span><span style="display:flex;"><span>        PGDATABASE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;[[ .TargetDB ]]&#34;</span>
</span></span><span style="display:flex;"><span>        AWS_REGION <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;eu-west-1&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><h2 id="testing-manual">Testing (Manual)</h2>
<p>The great thing about developing against Nomad is that testing is straightforward.  We can start a local copy by running <code>nomad agent -dev</code>, and then run our application locally to check it works properly, <em>before</em> needing to package it up into a Docker container and deploying it to a real cluster.  It also doesn&rsquo;t need to be packaged in a container for Nomad; we could use <a href="https://www.nomadproject.io/docs/drivers/exec">Isolated Exec</a> or <a href="https://www.nomadproject.io/docs/drivers/raw_exec">Raw Exec</a> too.)</p>
<p>There is a <code>start.sh</code> script in the repository which will use <code>tmux</code> to start 3 terminals, one to run a Nomad agent in dev mode (<code>nomad agent -dev</code>), one to build and run the operator (<code>go build &amp;&amp; ./operator</code>), and one to register and deregister nomad jobs.</p>
<p>When all is ready, submit the example job with the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad job run example.nomad
</span></span></code></pre></div><p>Will cause the following output in the operator&rsquo;s terminal:</p>
<pre tabindex="0"><code>==&gt; JobRegistered: example (pending)...
    Registering backup job
    Backup created: backup-example
--&gt; Done
==&gt; JobRegistered: backup-example (running)...
    Job is a backup, skipping
</code></pre><p>We can also check the Nomad UI, running on http://localhost:4646, which shows our two jobs:</p>
<p><img loading="lazy" src="nomad-backup-jobs.png" alt="nomad jobs showing the example service and the backup periodic job"  />
</p>
<p>Note how the <code>example</code> job is a <code>service</code>, which continuously runs, and the <code>backup-example</code> is a <code>periodic</code> job, scheduled to run daily.</p>
<p>Removing the example job  with the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad job stop example
</span></span></code></pre></div><p>This will be seen by the operator, which will remove the backup job:</p>
<pre tabindex="0"><code>==&gt; JobDeregistered: example (running)...
    Trying to remove a backup, if any
==&gt; JobDeregistered: backup-example (dead)...
    Job is a backup, skipping
</code></pre><p>Note how it also sees the <code>backup-example</code> job being deregistered and ignores it as, in our case, backups don&rsquo;t have backups!</p>
<h2 id="testing-automated">Testing (Automated)</h2>
<p>We can also write automated tests in two ways for this operator; Tests that run against a saved or synthetic event stream, and tests that work in the same way as the manual test; start Nomad, run a test suite; stop Nomad.</p>
<p>Reading from a file of known events, we can test the <code>handleEvent</code> function directly:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#a6e22e">seenEvents</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">string</span>{}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">c</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">NewConsumer</span>(<span style="color:#66d9ef">nil</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">eventType</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">job</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">Job</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">seenEvents</span> = append(<span style="color:#a6e22e">seenEvents</span>, <span style="color:#a6e22e">eventType</span>)
</span></span><span style="display:flex;"><span>})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">line</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">Split</span>(<span style="color:#a6e22e">eventsJson</span>, <span style="color:#e6db74">&#34;\n&#34;</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">var</span> <span style="color:#a6e22e">events</span> <span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">Events</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">json</span>.<span style="color:#a6e22e">Unmarshal</span>([]byte(<span style="color:#a6e22e">line</span>), <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">events</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">c</span>.<span style="color:#a6e22e">handleEvent</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">events</span>)
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">assert</span>.<span style="color:#a6e22e">Len</span>(<span style="color:#a6e22e">t</span>, <span style="color:#a6e22e">seenEvents</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">assert</span>.<span style="color:#a6e22e">Equal</span>(<span style="color:#a6e22e">t</span>, []<span style="color:#66d9ef">string</span>{<span style="color:#e6db74">&#34;JobRegistered&#34;</span>, <span style="color:#e6db74">&#34;JobDeregistered&#34;</span>}, <span style="color:#a6e22e">seenEvents</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The other way of testing is running a nomad instance in dev mode next to the application and registering jobs to it.  Usually, when doing this, I would start the Nomad application before running the tests and then stop it after, to save the time of waiting for Nomad to start between each test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#a6e22e">wait</span> <span style="color:#f92672">:=</span> make(<span style="color:#66d9ef">chan</span> <span style="color:#66d9ef">bool</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">client</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">NewClient</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">Config</span>{})
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">assert</span>.<span style="color:#a6e22e">NoError</span>(<span style="color:#a6e22e">t</span>, <span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">seenJobID</span> <span style="color:#f92672">:=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">c</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">NewConsumer</span>(<span style="color:#a6e22e">client</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">eventType</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">job</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">Job</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">seenJobID</span> = <span style="color:#f92672">*</span><span style="color:#a6e22e">job</span>.<span style="color:#a6e22e">ID</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">wait</span> <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">go</span> <span style="color:#a6e22e">c</span>.<span style="color:#a6e22e">Start</span>()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">//register a job
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#a6e22e">job</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">jobspec</span>.<span style="color:#a6e22e">Parse</span>(<span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">NewReader</span>(<span style="color:#a6e22e">withBackupHcl</span>))
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">assert</span>.<span style="color:#a6e22e">NoError</span>(<span style="color:#a6e22e">t</span>, <span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">client</span>.<span style="color:#a6e22e">Jobs</span>().<span style="color:#a6e22e">Register</span>(<span style="color:#a6e22e">job</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">api</span>.<span style="color:#a6e22e">WriteOptions</span>{})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// block until the job handler has run once
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">wait</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">assert</span>.<span style="color:#a6e22e">Equal</span>(<span style="color:#a6e22e">t</span>, <span style="color:#f92672">*</span><span style="color:#a6e22e">job</span>.<span style="color:#a6e22e">ID</span>, <span style="color:#a6e22e">seenJobID</span>)
</span></span></code></pre></div><p>As this is running against a real copy of Nomad, we need to wait for jobs to be registered and only stop our test once things have been processed; hence we use a <code>bool</code> channel to block until our job handler has seen a job.</p>
<p>In a real test suite, you would need to make the job handler filter to the specific job it is looking for; as this would prevent shared state issues (currently this will stop after <em>any</em> job is seen), and thus allow you to run the tests in parallel.</p>
<h2 id="deployment">Deployment</h2>
<p>No operator pattern would be complete without pushing the operator itself into the Nomad cluster, and while we <em>could</em> just run the binary directly in Nomad (utilising the <a href="https://www.nomadproject.io/docs/job-specification/artifact">Artifact Stanza</a> and <a href="https://www.nomadproject.io/docs/drivers/exec">Isolated Exec</a>), its probably easier to create a docker container.</p>
<p>We have a single <code>Dockerfile</code> with a multistage build so that our output container only contains the binary itself, rather than all the layers and intermediate artefacts from the build process:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-dockerfile" data-lang="dockerfile"><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> golang:1.16.10-alpine3.14 as builder</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">WORKDIR</span><span style="color:#e6db74"> /app</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> go.mod go.sum ./<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> go mod download<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> . ./<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> go build<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> alpine:3.14 as output</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> --from<span style="color:#f92672">=</span>builder /app/operator /usr/local/bin/operator<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div><p>Once the container is built and tagged:</p>
<pre tabindex="0"><code>docker build -t operator:local .
</code></pre><p>We can verify it works as intended by running the container directly; <code>--net=host</code> is passed to the <code>run</code> command so that the operator can connect to Nomad on <code>localhost:4646</code>, rather than having to pass in our host IP through an environment variable.  If you want to do this, add <code>-e NOMAD_ADDR=http://SOME_IP_OR_HOST:4646</code> to the <code>docker run</code> command:</p>
<pre tabindex="0"><code>docker run --rm -it --net=host operator:local
</code></pre><p>Assuming we&rsquo;re happy, we can run the Operator container in our local Nomad instance without pushing it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>task <span style="color:#e6db74">&#34;operator&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  config <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    image <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;operator:latest&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  template <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {{ with secret &#34;nomad/creds/operator-job&#34; }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    NOMAD_TOKEN={{ .Data.secret_id  | toJSON }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {{ end }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>    destination <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;secrets/db.env&#34;</span>
</span></span><span style="display:flex;"><span>    env <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  env <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    NOMAD_ADDR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;nomad.service.consul&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><h2 id="wrapping-up">Wrapping Up</h2>
<p>The Operator Pattern is a great way to handle everyday tasks that a cluster operator would normally, and I have used it to handle things like automatic backups, certificate generation (at least until Vault supports LetEncrypt), and job cleanup (for example, developer branch builds only stay in the cluster for 3 days.)</p>
]]></content:encoded></item><item><title>Service Mesh with Consul Connect (and Nomad)</title><link>https://andydote.co.uk/2020/05/04/service-mesh-consul-connect/</link><pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate><guid>https://andydote.co.uk/2020/05/04/service-mesh-consul-connect/</guid><description>When it comes to implementing a new feature in an application&amp;rsquo;s ecosystem, I don&amp;rsquo;t like spending my innovation tokens unless I have to, so I try not to add new tools to my infrastructure unless I really need them.
This same approach comes when I either want, need, or have been told, to implement a Service Mesh. This means I don&amp;rsquo;t instantly setup Istio. Not because it&amp;rsquo;s bad - far from it - but because it&amp;rsquo;s extra complexity I would rather avoid, unless I need it.</description><content:encoded><![CDATA[<p>When it comes to implementing a new feature in an application&rsquo;s ecosystem, I <a href="https://mcfunley.com/choose-boring-technology">don&rsquo;t like spending my innovation tokens</a> unless I have to, so I try not to add new tools to my infrastructure unless I <em>really</em> need them.</p>
<p>This same approach comes when I either want, need, or have been told, to implement a Service Mesh.  This means I don&rsquo;t instantly setup <a href="https://istio.io/">Istio</a>.  Not because it&rsquo;s bad - far from it - but because it&rsquo;s extra complexity I would rather avoid, unless I need it.</p>
<p>But what alternatives are there?</p>
<p>In most large systems I have been involved with <a href="https://www.consul.io">Consul</a> has been deployed;  usually for Service Discovery, <a href="/2018/09/06/consul-feature-toggles/">Feature Toggles</a>, it&rsquo;s key-value store, or distributed locking.  As Consul has Service Mesh functionality built in, why not use that?</p>
<p>So let&rsquo;s dive into setting up a <a href="https://www.consul.io/docs/connect/index.html">Consul Connect</a> based Service Mesh.</p>
<h2 id="implementing">Implementing</h2>
<p>The demo for this is made up of two parts (taken from HashiCorp&rsquo;s consul demo repo): a counter and a dashboard.  The counter listens for HTTP requests and will return the number of requests it&rsquo;s handled.  The dashboard polls the counter and displays the current count.</p>
<p>All the source code for the demo is in the <a href="https://github.com/Pondidum/consul-connect-nomad-demo">Consul Connect Example Repository</a>.</p>
<p>Clone the repository, and run the build script to create the apps:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Pondidum/consul-connect-nomad-demo
</span></span><span style="display:flex;"><span>cd consul-connect-nomad-demo
</span></span><span style="display:flex;"><span>./apps/build.sh
</span></span></code></pre></div><h3 id="local-run">Local Run</h3>
<p>Run the apps locally to prove they work, in two separate terminals:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>PORT<span style="color:#f92672">=</span><span style="color:#ae81ff">9001</span> ./apps/bin/counter
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>PORT<span style="color:#f92672">=</span><span style="color:#ae81ff">9002</span> ./apps/bin/dashboard
</span></span></code></pre></div><p>Open <code>http://localhost:9002</code> to see the counter running.</p>
<h3 id="start-a-cluster">Start A Cluster</h3>
<p>Now we have established our apps actually start, we can create a small Consul cluster.  I am using my Hashibox to do this, so you&rsquo;ll need libvirt and Vagrant installed to do this.</p>
<p>Running <code>vagrant up</code> will spawn three machines, which will form a Consul cluster, which we can now experiment in.  Once it is up and running, we can manually register the two applications into Consul&rsquo;s service mesh to check that our in cluster communication works.</p>
<p>First, the counter service.  The script writes a service definition into consul, which, by specifying the <code>connect</code> stanza, indicates this service is to be included in the service mesh.  Once this is done, the counter is started (and sent to the background), and a consul connect proxy is started for this service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl --request PUT --url http://localhost:8500/v1/agent/service/register <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --data <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;name&#34;: &#34;counter&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;port&#34;: 9001,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;connect&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;sidecar_service&#34;: {}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  }&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>PORT<span style="color:#f92672">=</span><span style="color:#ae81ff">9001</span> /vagrant/apps/bin/counter &amp;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>consul connect proxy -sidecar-for counter
</span></span></code></pre></div><p>We can run this script in a new terminal by running this command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vagrant ssh one -c <span style="color:#e6db74">&#39;/vagrant/scripts/counter.sh&#39;</span>
</span></span></code></pre></div><p>Finally, we start the dashboard.  The script is very similar, in that we write a service definiton into consul, start the service and run a proxy.  The only notable difference is the service registation payload itself:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;dashboard&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;port&#34;</span>: <span style="color:#ae81ff">9002</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;connect&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;sidecar_service&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;proxy&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;upstreams&#34;</span>: [
</span></span><span style="display:flex;"><span>          { <span style="color:#f92672">&#34;destination_name&#34;</span>: <span style="color:#e6db74">&#34;counter&#34;</span>, <span style="color:#f92672">&#34;local_bind_port&#34;</span>: <span style="color:#ae81ff">8080</span> }
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As before, it registers a service, and on what port it will be listening on, but in the <code>connect</code> stanza, we specify that we want to connect to the <code>counter</code>, and we want to talk to it on <code>localhost:8080</code>.</p>
<p>In a new terminal, you can run this script like so:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vagrant ssh two -c <span style="color:#e6db74">&#39;/vagrant/scripts/dashboard.sh&#39;</span>
</span></span></code></pre></div><p>Now that both are up and running, you can open a browser to the dashboard and see it working: <code>http://two.karhu.xyz:9002</code>.  Once you are satisfied, you can stop the services by hitting <code>ctrl+c</code> in both terminals&hellip;or try running a second counter or dashboard on the third vagrant machine (<code>vagrant ssh three -c '/vagrant/scripts/dashboard.sh'</code>)</p>
<h3 id="nomad">Nomad</h3>
<p>Now that we have seen how to run the services manually let&rsquo;s see how easy it is to use the service mesh using <a href="https://nomadproject.io">Nomad</a>.</p>
<p>There are two nomad job definitions in the included project, so let&rsquo;s look at the counter&rsquo;s first:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#a6e22e">job</span> <span style="color:#e6db74">&#34;counter&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">datacenters</span> = [<span style="color:#e6db74">&#34;dc1&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">group</span> <span style="color:#e6db74">&#34;api&#34;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">count</span> = <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">network</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">mode</span> = <span style="color:#e6db74">&#34;bridge&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">service</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">name</span> = <span style="color:#e6db74">&#34;count-api&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">port</span> = <span style="color:#e6db74">&#34;9001&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">connect</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">sidecar_service</span> {}
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">task</span> <span style="color:#e6db74">&#34;counter&#34;</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">driver</span> = <span style="color:#e6db74">&#34;exec&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">config</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">command</span> = <span style="color:#e6db74">&#34;/vagrant/apps/bin/counter&#34;</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">env</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">PORT</span> = <span style="color:#ae81ff">9001</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>network</code> stanza is set to <code>bridge</code> mode, which creates us an isolated network between all the services in the group only.  In our case, we will have a single <code>counter</code> service and the proxy.</p>
<p>The <code>service</code> stanza is replicating the same functionality we had by writing a service registration into Consul.  By specifying the <code>connect</code> part, Nomad knows that it also needs to start a proxy-based on the service stanza&rsquo;s settings, and will handle starting and stopping this proxy for us.</p>
<p>The <code>task &quot;counter&quot;</code> block uses the <code>exec</code> driver to run the counter app natively on the host, but <code>docker</code>, <code>java</code>, and others are available too.</p>
<p>To run this into our Nomad cluster, we can use the nomad CLI:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export NOMAD_ADDR<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://one.karhu.xyz:4646&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nomad job run apps/counter/counter.nomad
</span></span></code></pre></div><p>The dashboard&rsquo;s Nomad job is very similar:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#a6e22e">job</span> <span style="color:#e6db74">&#34;dashboard&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">datacenters</span> = [<span style="color:#e6db74">&#34;dc1&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">group</span> <span style="color:#e6db74">&#34;dashboard&#34;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">network</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">mode</span> = <span style="color:#e6db74">&#34;bridge&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">port</span> <span style="color:#e6db74">&#34;http&#34;</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">to</span>     = <span style="color:#ae81ff">9002</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">service</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">name</span> = <span style="color:#e6db74">&#34;count-dashboard&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">port</span> = <span style="color:#ae81ff">9002</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">connect</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">sidecar_service</span> {
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">proxy</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#a6e22e">upstreams</span> {
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">destination_name</span> = <span style="color:#e6db74">&#34;count-api&#34;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">local_bind_port</span>  = <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">task</span> <span style="color:#e6db74">&#34;dashboard&#34;</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">driver</span> = <span style="color:#e6db74">&#34;exec&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">config</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">command</span> = <span style="color:#e6db74">&#34;/vagrant/apps/bin/dashboard&#34;</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">env</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">PORT</span> = <span style="color:#e6db74">&#34;${NOMAD_PORT_http}&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">COUNTING_SERVICE_URL</span> = <span style="color:#e6db74">&#34;http://${NOMAD_UPSTREAM_ADDR_count_api}&#34;</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>network</code> block this time also specifies that we want to expose our service to the public.  As we don&rsquo;t have a <code>static = 9002</code> in the port definition, Nomad will assign one at random (this is better! You can avoid port clashes with multiple tasks on the same node), we do however specify that we will map to <code>9002</code>.  The rest of the file can use the Nomad variable <code>NOMAD_PORT_http</code> to get this port number, so we don&rsquo;t have to copy-paste the number everywhere.  Similarly, the <code>sidecar_service</code> stanza exposes a variable called <code>NOMAD_UPSTREAM_ADDR_&lt;destination_name&gt;</code>, so we can use that too for our dashboard task&rsquo;s environment variable values. This means we should only ever need to specify ports in 1 location in a Nomad file.</p>
<p>As with the counter, we can run the job using the CLI:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad job run apps/counter/dashboard.nomad
</span></span></code></pre></div><p>If we want to get the address and port the dashboard is actually running at, it is easiest to go through the UI, but you can also get the information from the console using the Nomad CLI and jq:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>allocation_id<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>nomad alloc status -json | jq -r <span style="color:#e6db74">&#39;.[] | select(.JobID == &#34;dashboard&#34;) | .ID&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nomad alloc status -json <span style="color:#e6db74">&#34;</span>$allocation_id<span style="color:#e6db74">&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  | jq -r <span style="color:#e6db74">&#39;.AllocatedResources.Shared.Networks[0] | ( &#34;http://&#34; + .IP + &#34;:&#34; + (.DynamicPorts[] | select(.Label == &#34;http&#34;) | .Value | tostring))&#39;</span>
</span></span></code></pre></div><h2 id="wrapping-up">Wrapping Up</h2>
<p>With Consul Connect&rsquo;s supported APIs, there is great flexibility in how you can implement your service mesh; through definition files, through API requests, or through the container orchestrator directly.  Couple this with Consul already being in use in most systems I have been involved with, and hopefully you can see why it makes a great way of having a Service Mesh.</p>
]]></content:encoded></item><item><title>Nomad Isolated Exec</title><link>https://andydote.co.uk/2020/02/29/nomad-isolated-exec/</link><pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate><guid>https://andydote.co.uk/2020/02/29/nomad-isolated-exec/</guid><description>One of the many features of Nomad that I like is the ability to run things other than Docker containers. It has built-in support for Java, QEMU, and Rkt, although the latter is deprecated. Besides these inbuilt &amp;ldquo;Task Drivers&amp;rdquo; there are community maintained ones too, covering Podman, LXC, Firecraker and BSD Jails, amongst others.
The one I want to talk about today, however, is called exec. This Task Driver runs any given executable, so if you have an application which you don&amp;rsquo;t want (or can&amp;rsquo;t) put into a container, you can still schedule it with Nomad.</description><content:encoded><![CDATA[<p>One of the many features of <a href="https://nomadproject.io">Nomad</a> that I like is the ability to run things other than Docker containers.  It has built-in support for Java, QEMU, and Rkt, although the latter is deprecated.  Besides these inbuilt &ldquo;Task Drivers&rdquo; there are community maintained ones too, covering Podman, LXC, Firecraker and BSD Jails, amongst others.</p>
<p>The one I want to talk about today, however, is called <code>exec</code>.  This Task Driver runs any given executable, so if you have an application which you don&rsquo;t want (or can&rsquo;t) put into a container, you can still schedule it with Nomad.  When I run demos (particularly at conferences), I try to have everything runnable without an internet connection, which means I have to make sure all the Docker containers I wish to run are within a local Docker Registry already, and, well, sometimes I forget.  By using <code>exec</code>, I can serve a binary off my machine with no container overheads involved.</p>
<h2 id="insecurity">Insecurity?</h2>
<p>Until recently, I had always considered <code>exec</code> as a tradeoff: I don&rsquo;t need a docker container, but I lose the isolation of the container, and the application I run has full access to everything on this host.</p>
<p>What I hadn&rsquo;t realised, is that <code>exec</code> actually uses the host operating system&rsquo;s isolation features via the <a href="https://pkg.go.dev/github.com/opencontainers/runc/libcontainer?tab=doc">libcontainer</a> package to contain the application.  On Linux, this means using <code>cgroups</code> and a <code>chroot</code>, making the level of isolation roughly the same as a docker container provides.</p>
<p>When you specify a binary to run, it must meet a few criteria:</p>
<ul>
<li>An absolute path within Nomad&rsquo;s <code>chroot</code></li>
<li>A relative path within the Allocation Directory</li>
</ul>
<p>For instance, to run a dotnet core application consists of invoking <code>/usr/bin/dotnet</code> with the relative path of the dll extracted from the artifact:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>task <span style="color:#e6db74">&#34;consumer&#34;</span> {
</span></span><span style="display:flex;"><span>    driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;exec&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    config {
</span></span><span style="display:flex;"><span>        command <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/usr/bin/dotnet&#34;</span>
</span></span><span style="display:flex;"><span>        args <span style="color:#f92672">=</span> <span style="color:#f92672">[</span> <span style="color:#e6db74">&#34;local/Consumer.dll&#34;</span> <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    artifact {
</span></span><span style="display:flex;"><span>        source <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://s3.internal.net/consumer-dotnet.zip&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Whereas running a go binary can be done with a path relative to the allocation directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>task <span style="color:#e6db74">&#34;consumer&#34;</span> {
</span></span><span style="display:flex;"><span>    driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;exec&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    config {
</span></span><span style="display:flex;"><span>        command <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;local/consumer&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    artifact {
</span></span><span style="display:flex;"><span>        source <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://s3.internal.net/consumer-go.zip&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>But what happens if we want to run a binary which is not within the default chroot environment used by <code>exec</code>?</p>
<h2 id="configuring-the-chroot-environment">Configuring The chroot Environment</h2>
<p>By default, Nomad links the following paths into the task&rsquo;s chroot:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>[
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/bin&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/etc&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/lib&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/lib32&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/lib64&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/run/resolvconf&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/sbin&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/usr&#34;</span>
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>We can configure the <code>chroot</code> per Nomad client, meaning we can provision nodes with different capabilities if necessary.  This is done with the <code>chroot_env</code> setting in the client&rsquo;s configuration file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>client {
</span></span><span style="display:flex;"><span>  chroot_env {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/bin&#34;</span>            <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/bin&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/etc&#34;</span>            <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/etc&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/lib&#34;</span>            <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/lib&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/lib32&#34;</span>          <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/lib32&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/lib64&#34;</span>          <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/lib64&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/run/resolvconf&#34;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/run/resolvconf&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/sbin&#34;</span>           <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/sbin&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/usr&#34;</span>            <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/usr&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/vagrant&#34;</span>        <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/vagrant&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>In this case, I have added in the <code>/vagrant</code> path, which is useful as I usually provision a Nomad cluster using <a href="https://vagrantup.com">Vagrant</a>, and thus have all my binaries etc. available in <code>/vagrant</code>.  It means that my <code>.nomad</code> files for the demo have something like this for their tasks:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>task <span style="color:#e6db74">&#34;dashboard&#34;</span> {
</span></span><span style="display:flex;"><span>    driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;exec&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    config {
</span></span><span style="display:flex;"><span>        command <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/vagrant/apps/bin/dashboard&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Meaning I don&rsquo;t need to host a Docker Registry, or HTTP server to expose my applications to the Nomad cluster.</p>
<h2 id="need-full-access">Need Full Access?</h2>
<p>If you need full access to the host machine, you can use the non-isolating version of <code>exec</code>, called <code>raw_exec</code>.  <code>raw_exec</code> works in the same way as <code>exec</code>, but without using <code>cgroups</code> and <code>chroot</code>.  As this would be a security risk, it must be enabled on each Nomad client:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>client {
</span></span><span style="display:flex;"><span>    enabled <span style="color:#f92672">=</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plugin <span style="color:#e6db74">&#34;raw_exec&#34;</span> {
</span></span><span style="display:flex;"><span>    config {
</span></span><span style="display:flex;"><span>        enabled <span style="color:#f92672">=</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="wrapping-up">Wrapping Up</h2>
<p>One of the many reasons I like Nomad is its simplicity, especially when compared to something as big and complex as Kubernetes.  Whenever I look into how Nomad works, I always seem to come away with the feeling that it has been well thought out, and how flexible it is because of this.</p>
<p>Being able to configure the chroot used by the Nomad clients means I can simplify my various demos further, as I can remove the need to have a webserver for an artifact source. As always, the less accidental complexity you have in your system, the better.</p>
]]></content:encoded></item><item><title>Nomad Good, Kubernetes Bad</title><link>https://andydote.co.uk/2019/11/21/nomad-good-kubernetes-bad/</link><pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate><guid>https://andydote.co.uk/2019/11/21/nomad-good-kubernetes-bad/</guid><description>I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don&amp;rsquo;t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator at all.
TLDR: I don&amp;rsquo;t like complexity, and Kubernetes has more complexity than benefits.
Operational Complexity Operating Nomad is very straight forward. There are very few moving parts, so the number of things which can go wrong is significantly reduced.</description><content:encoded><![CDATA[<p>I will update this post as I learn more (both positive and negative), and is here to be linked to when people ask me why I don&rsquo;t like Kubernetes, and why I would pick Nomad in most situations if I chose to use an orchestrator <em>at all</em>.</p>
<p>TLDR: I don&rsquo;t like complexity, and Kubernetes has more complexity than benefits.</p>
<h3 id="operational-complexity">Operational Complexity</h3>
<p>Operating Nomad is very straight forward.  There are very few moving parts, so the number of things which can go wrong is significantly reduced.  No external dependencies are required to run it, and there is only one binary to use.  You run 3-5 copies in Server mode to manage the cluster and as many as you want running in Client mode to do the actual work.  You can add Consul if you want service discovery, but it&rsquo;s optional.  More on that later.</p>
<p>Compare this to operating a Kubernetes cluster.  There are multiple Kubernetes orchestration projects, tools, and companies to get clusters up and running, which should be an indication of the level of complexity involved.  Once you have the cluster set up, you need to keep it running.  There are so many moving parts (Controller Manager, Scheduler, API Server, Etcd, Kubelets) that it quickly becomes a full-time job to keep the cluster up and running.  Use a cloud service to run Kubernetes, and if you must use your own infrastructure, pay someone else to manage it.  It&rsquo;s cheaper in the long run. Trust me.</p>
<h3 id="deployment">Deployment</h3>
<p>Nomad, being a single binary, is easy to deploy.  If you want to use <a href="https://www.terraform.io/">Terraform</a> to create a cluster, Hashicorp provides modules for both <a href="https://github.com/hashicorp/terraform-aws-nomad">AWS</a> and <a href="https://github.com/hashicorp/terraform-azurerm-nomad">Azure</a>.  Alternatively, you can do everything yourself, as it&rsquo;s just keeping one binary running on hosts, and a bit of network/DNS config to get them talking to each other.</p>
<p>By comparison, Kubernetes has a multitude of tools to help you deploy a cluster. Still, while it gives you a lot of flexibility in choice, you also have to hope that the tool continues to exist and that there is enough community/company/documentation about that specific tool to help you when something goes wrong.</p>
<h3 id="upgrading-the-cluster">Upgrading The Cluster</h3>
<p>Upgrading Nomad involves doing a rolling deployment of the Servers and Clients.  If you are using the Hashicorp Terraform module, you re-apply the module with the new AMI ID to use, and then delete nodes (gracefully!) from the cluster and let the AutoScaleGroup take care of bringing new nodes up.  If you need to revert to an older version of Nomad, you follow the same process.</p>
<p>When it comes to Kubernetes, please pay someone else to do it.  It&rsquo;s not a fun process.  The process will differ depending on which cluster management tool you are using, and you also need to think about updates to etcd and managing state in the process.  There is a <a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/">nice long document</a> on how to upgrade etcd.</p>
<h3 id="debugging-a-cluster">Debugging a Cluster</h3>
<p>As mentioned earlier, Nomad has a small number of moving parts.  There are three ports involved (HTTP, RPC and Gossip), so as long as those ports are open and reachable, Nomad should be operable.  Then you need to keep the Nomad agents alive.  That&rsquo;s pretty much it.</p>
<p>Where to start for Kubernetes? As many <a href="https://github.com/hjacobs/kubernetes-failure-stories">Kubernetes Failure Stories</a> point out: it&rsquo;s always DNS. Or etcd. Or Istio. Or networking. Or Kubelets. Or all of these.</p>
<h3 id="local-development">Local Development</h3>
<p>To run Nomad locally, you use the same binary as the production clusters, but in dev mode: <code>nomad agent -dev</code>.  To get a local cluster, you can spin up some Vagrant boxes instead.  I use my <a href="https://github.com/pondidum/hashibox">Hashibox</a> Vagrant box to do this when I do conference talks and don&rsquo;t trust the wifi to work.</p>
<p>To run Kubernetes locally to test things, you need to install/deploy MiniKube, K3S, etc.  The downside to this approach is that the environment is significantly different to your real Kubernetes cluster, and you can end up where a deployment works in one, but not the other, which makes debugging issues much harder.</p>
<h3 id="features--choice">Features &amp; Choice</h3>
<p>Nomad is relatively light on built-in features, which allows you the choice of what features to add, and what implementations of the features to use.  For example, it is pretty popular to use Consul for service discovery, but if you would rather use <a href="https://github.com/Netflix/eureka">Eureka</a>, or Zookeeper, or even etcd, that is fine, but you lose out on the seamless integration with Nomad that other Hashicorp tools have.  Nomad also supports <a href="https://www.nomadproject.io/docs/internals/plugins/index.html">Plugins</a> if you want to add support for your favourite tool.</p>
<p>By comparison, Kubernetes does everything, but like the phrase &ldquo;Jack of all trades, master of none&rdquo;, often you will have to supplement the inbuilt features.  The downside to this is that you can&rsquo;t switch off Kubernetes features you are not using, or don&rsquo;t want.  So if you add Vault for secret management, the Kubernetes Secrets are still available, and you have to be careful that people don&rsquo;t use them accidentally.  The same goes for all other features, such as Load Balancing, Feature Toggles, Service Discovery, DNS, etc.</p>
<h3 id="secret-management">Secret Management</h3>
<p>Nomad doesn&rsquo;t provide a Secret Management solution out of the box, but it does have seamless Vault integration, and you are also free to use any other Secrets As A Service tool you like.  If you do choose Vault, you can either use it directly from your tasks or use Nomad&rsquo;s integration to provide the secrets to your application.  It can even send a signal (e.g. <code>SIGINT</code> etc.) to your process when the secrets need re-reading.</p>
<p>Kubernetes, on the other hand, provides &ldquo;Secrets&rdquo;.  I put the word &ldquo;secrets&rdquo; in quotes because they are not secrets at all. The values are stored encoded in base64 in etcd, so anyone who has access to the etcd cluster has access to <em>all</em> the secrets.  The <a href="https://kubernetes.io/docs/concepts/configuration/secret/#risks">official documentation</a> suggests making sure only administrators have access to the etcd cluster to solve this.  Oh, and if you can deploy a container to the same namespace as a secret, you can reveal it by writing it to stdout.</p>
<blockquote>
<p>Kubernetes secrets are not secret, just &ldquo;slightly obscured.&rdquo;</p>
</blockquote>
<p>If you want real Secrets, you will almost certainly use Vault.  You can either run it inside or outside of Kubernetes, and either use it directly from containers via it&rsquo;s HTTPS API or use it to populate Kubernetes Secrets.  I&rsquo;d avoid populating Kubernetes Secrets if I were you.</p>
<h3 id="support">Support</h3>
<p>If Nomad breaks, you can either use community support or if you are using the Enterprise version, you have Hashicorp&rsquo;s support.</p>
<p>When Kubernetes breaks, you can either use community support or find and buy support from a Kubernetes management company.</p>
<p>The main difference here is &ldquo;when Kubernetes breaks&rdquo; vs &ldquo;if Nomad breaks&rdquo;.  The level of complexity in Kubernetes makes it far more likely to break, and that much harder to debug.</p>
]]></content:encoded></item><item><title>Canary Routing with Traefik in Nomad</title><link>https://andydote.co.uk/2019/06/23/nomad-traefik-canary/</link><pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate><guid>https://andydote.co.uk/2019/06/23/nomad-traefik-canary/</guid><description>I wanted to implement canary routing for some HTTP services deployed via Nomad the other day, but rather than having the traffic split by weighting to the containers, I wanted to direct the traffic based on a header.
My first choice of tech was to use Fabio, but it only supports routing by URL prefix, and additionally with a route weight. While I was at JustDevOps in Poland, I heard about another router/loadbalancer which worked in a similar way to Fabio: Traefik.</description><content:encoded><![CDATA[<p>I wanted to implement canary routing for some HTTP services deployed via <a href="https://www.nomadproject.io/">Nomad</a> the other day, but rather than having the traffic split by weighting to the containers, I wanted to direct the traffic based on a header.</p>
<p>My first choice of tech was to use <a href="https://fabiolb.net/">Fabio</a>, but it only supports routing by URL prefix, and additionally with a route weight.  While I was at <a href="https://justdevops.org/">JustDevOps</a> in Poland, I heard about another router/loadbalancer which worked in a similar way to Fabio: <a href="https://traefik.io/">Traefik</a>.</p>
<p>While Traefik also doesn&rsquo;t directly support canary routing, it is much more flexible than Fabio, also allowing request filtering based on HTTP headers.  Traefik integrates with a number of container schedulers directly, but Nomad is not one of them.  It does however also support using the Consul Service Catalog so that you can use it as an almost drop-in replacement for Fabio.</p>
<p>So let&rsquo;s get to the setup.  As usual, there is a complete repository on GitHub: <a href="https://github.com/Pondidum/nomad-traefik-canary-demo">Nomad Traefik Canary Routing</a>.</p>
<h2 id="nomad">Nomad</h2>
<p>As usual, I am using my <a href="https://github.com/Pondidum/hashibox">Hashibox</a> <a href="https://vagrantup.com/">Vagrant</a> base image, and provisioning it as a single Nomad server and client node, using <a href="https://github.com/Pondidum/nomad-traefik-canary-demo/blob/master/scripts/server.sh">this script</a>.  I won&rsquo;t dig into all the setup in that, as I&rsquo;ve written it a few times now.</p>
<h2 id="consul">Consul</h2>
<p>Consul is already running on the Hashibox base, so we have no further configuration to do.</p>
<h2 id="traefik">Traefik</h2>
<p>Traefik can be deployed as a Docker container, and either configured through a TOML file (yay, <a href="https://noyaml.com/">not yaml!</a>) or with command line switches.  As we only need a minimal configuration, I opted to use the command line.</p>
<p>The container exposes two ports we need to care about: <code>80</code> for incoming traffic to be routed, and <code>8080</code> for the UI, which are statically allocated to the host as <code>8000</code> and <code>8080</code> for this demo.</p>
<p>The command line configuration used is as follows:</p>
<ul>
<li><code>--api</code> - enable the UI.</li>
<li><code>--consulcatalog</code> - Traefik has two ways to use Consul - <code>--consul</code> uses the KV store for service definitions, and <code>--consulcatalog</code> makes use Consul&rsquo;s service catalogue.</li>
<li><code>--consulcatalog.endpoint=consul.service.consul:8500</code> as Consul is not running in the same container as Traefik, we need to tell it where Consul is listening, and as we have <a href="">DNS Forwarding for <code>*.consul</code> domains</a>, we use the address <code>consul.service.consul</code>.  If DNS forwarding was not available, you could use the Nomad variable <code>${attr.unique.network.ip-address}</code> to get the current task&rsquo;s host&rsquo;s IP.</li>
<li><code>--consulcatalog.frontEndRule</code> disable the default rule - each service needs to specify <code>traefik.frontend.rule</code>.</li>
<li><code>--consulcatalog.exposedByDefault=false</code> - lastly, we stop Traefik showing all services registered into consul, the will need to have the <code>traefik.enable=true</code> tag to be processed.</li>
</ul>
<p>The entire job file is listed below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>job <span style="color:#e6db74">&#34;traefik&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  datacenters <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;dc1&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;service&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  group <span style="color:#e6db74">&#34;loadbalancers&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    task <span style="color:#e6db74">&#34;traefik&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      config <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        image <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;traefik:1.7.12&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        args <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;--api&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;--consulcatalog&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;--consulcatalog.endpoint=consul.service.consul:8500&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;--consulcatalog.frontEndRule=&#39;&#39;&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;--consulcatalog.exposedByDefault=false&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        port_map <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>          http <span style="color:#f92672">=</span> <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>          ui <span style="color:#f92672">=</span> <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      resources <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        network <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;http&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">8000</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;ui&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">8080</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        memory <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>We register the job into Nomad, and then start on the backend services we will route to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad job run jobs/traefik.nomad
</span></span></code></pre></div><h2 id="the-backend-services">The Backend Services</h2>
<p>To demonstrate the services can be routed to correctly, we can use the <code>containersol/k8s-deployment-strategies</code> docker container.  This image exposes an HTTP service which responds with the container&rsquo;s hostname and the content of the <code>VERSION</code> environment variable, something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ curl http://echo.service.consul:8080
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Host: 23351e48dc98, Version: 1.0.0</span>
</span></span></code></pre></div><p>We&rsquo;ll start by making a standard nomad job for this container, and then update it to support canarying.  The entire job is listed below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>job <span style="color:#e6db74">&#34;echo&#34;</span> {
</span></span><span style="display:flex;"><span>  datacenters <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;dc1&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;service&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  group <span style="color:#e6db74">&#34;apis&#34;</span> {
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    task <span style="color:#e6db74">&#34;echo&#34;</span> {
</span></span><span style="display:flex;"><span>      driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      config {
</span></span><span style="display:flex;"><span>        image <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;containersol/k8s-deployment-strategies&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        port_map {
</span></span><span style="display:flex;"><span>          http <span style="color:#f92672">=</span> <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      env {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">VERSION</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1.0.0&#34;</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      resources {
</span></span><span style="display:flex;"><span>        network {
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;http&#34;</span> { }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      service {
</span></span><span style="display:flex;"><span>        name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;echo&#34;</span>
</span></span><span style="display:flex;"><span>        port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        tags <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;traefik.enable=true&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;traefik.frontend.rule=Host:api.localhost&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        check {
</span></span><span style="display:flex;"><span>          type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>          path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>          interval <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;5s&#34;</span>
</span></span><span style="display:flex;"><span>          timeout <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1s&#34;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The only part of interest in this version of the job is the <code>service</code> stanza, which is registering our echo service into consul, with a few tags to control how it is routed by Traefik:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>service {
</span></span><span style="display:flex;"><span>  name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;echo&#34;</span>
</span></span><span style="display:flex;"><span>  port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  tags <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;traefik.enable=true&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;traefik.frontend.rule=Host:api.localhost&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  check {
</span></span><span style="display:flex;"><span>    type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>    path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>    interval <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;5s&#34;</span>
</span></span><span style="display:flex;"><span>    timeout <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1s&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>traefik.enabled=true</code> tag allows this service to be handled by Traefik (as we set <code>exposedByDefault=false</code> in Traefik), and <code>traefik.frontend.rule=Host:api.localhost</code> the rule means that any traffic with the <code>Host</code> header set to <code>api.localhost</code> will be routed to the service.</p>
<p>Which we can now run the job in Nomad:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad job run jobs/echo.nomad
</span></span></code></pre></div><p>Once it is up and running, we&rsquo;ll get 3 instances of <code>echo</code> running which will be round-robin routed by Traefik:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ curl http://traefik.service.consul:8080 -H <span style="color:#e6db74">&#39;Host: api.localhost&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Host: 1ac8a49cbaee, Version: 1.0.0</span>
</span></span><span style="display:flex;"><span>$ curl http://traefik.service.consul:8080 -H <span style="color:#e6db74">&#39;Host: api.localhost&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Host: 23351e48dc98, Version: 1.0.0</span>
</span></span><span style="display:flex;"><span>$ curl http://traefik.service.consul:8080 -H <span style="color:#e6db74">&#39;Host: api.localhost&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Host: c2f8a9dcab95, Version: 1.0.0</span>
</span></span></code></pre></div><p>Now that we have working routing for the Echo service let&rsquo;s make it canaryable.</p>
<h2 id="canaries">Canaries</h2>
<p>To show canary routing, we will create a second version of the service to respond to HTTP traffic with a <code>Canary</code> header.</p>
<p>The first change to make is to add in the <code>update</code> stanza, which controls how the containers get updated when Nomad pushes a new version.  The <code>canary</code> parameter controls how many instances of the task will be created for canary purposes (and must be less than the total number of containers).  Likewise, the <code>max_parallel</code> parameter controls how many containers will be replaced at a time when a deployment happens.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span>group &#34;apis&#34; {
</span></span><span style="display:flex;"><span>  count = 3
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">+  update {
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+    max_parallel = 1
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+    canary = 1
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+  }
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e"></span>
</span></span><span style="display:flex;"><span>  task &#34;echo&#34; {
</span></span></code></pre></div><p>Next, we need to modify the <code>service</code> stanza to write different tags to Consul when a task is a canary instance so that it does not get included in the &ldquo;normal&rdquo; backend routing group.</p>
<p>If we don&rsquo;t specify at least 1 value in <code>canary_tags</code>, Nomad will use the <code>tags</code> even in the canary version - an empty <code>canary_tags = []</code> declaration is not enough!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span>service {
</span></span><span style="display:flex;"><span>  name = &#34;echo&#34;
</span></span><span style="display:flex;"><span>  port = &#34;http&#34;
</span></span><span style="display:flex;"><span>  tags = [
</span></span><span style="display:flex;"><span>    &#34;traefik.enable=true&#34;,
</span></span><span style="display:flex;"><span>    &#34;traefik.frontend.rule=Host:api.localhost&#34;
</span></span><span style="display:flex;"><span>  ]
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">+  canary_tags = [
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+    &#34;traefik.enable=false&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+  ]
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e"></span>  check {
</span></span></code></pre></div><p>Finally, we need to add a separate <code>service</code> stanza to create a second backend group which will contain the canary versions.  Note how this group has a different name, and has no <code>tags</code>, but does have a set of <code>canary_tags</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>service {
</span></span><span style="display:flex;"><span>  name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;echo-canary&#34;</span>
</span></span><span style="display:flex;"><span>  port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>  tags <span style="color:#f92672">=</span> <span style="color:#f92672">[]</span>
</span></span><span style="display:flex;"><span>  canary_tags <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;traefik.enable=true&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;traefik.frontend.rule=Host:api.localhost;Headers: Canary,true&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  check {
</span></span><span style="display:flex;"><span>    type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>    path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>    interval <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;5s&#34;</span>
</span></span><span style="display:flex;"><span>    timeout <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1s&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The reason we need two <code>service</code> stanzas is that Traefik can only create backends based on the name of the service registered to Consul and not from a tag in that registration.  If we just used one <code>service</code> stanza, then the canary version of the container would be added to both the canary backend and standard backend.  I was hoping for <code>traefik.backend=echo-canary</code> to work, but alas no.</p>
<p>The entire updated jobfile is as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>job <span style="color:#e6db74">&#34;echo&#34;</span> {
</span></span><span style="display:flex;"><span>  datacenters <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;dc1&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;service&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  group <span style="color:#e6db74">&#34;apis&#34;</span> {
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    update {
</span></span><span style="display:flex;"><span>      max_parallel <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>      canary <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    task <span style="color:#e6db74">&#34;echo&#34;</span> {
</span></span><span style="display:flex;"><span>      driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      config {
</span></span><span style="display:flex;"><span>        image <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;containersol/k8s-deployment-strategies&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        port_map {
</span></span><span style="display:flex;"><span>          http <span style="color:#f92672">=</span> <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      env {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">VERSION</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1.0.0&#34;</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      resources {
</span></span><span style="display:flex;"><span>        network {
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;http&#34;</span> { }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        memory <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      service {
</span></span><span style="display:flex;"><span>        name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;echo-canary&#34;</span>
</span></span><span style="display:flex;"><span>        port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        tags <span style="color:#f92672">=</span> <span style="color:#f92672">[]</span>
</span></span><span style="display:flex;"><span>        canary_tags <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;traefik.enable=true&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;traefik.frontend.rule=Host:api.localhost;Headers: Canary,true&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        check {
</span></span><span style="display:flex;"><span>          type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>          path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>          interval <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;5s&#34;</span>
</span></span><span style="display:flex;"><span>          timeout <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1s&#34;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      service {
</span></span><span style="display:flex;"><span>        name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;echo&#34;</span>
</span></span><span style="display:flex;"><span>        port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        tags <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;traefik.enable=true&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;traefik.frontend.rule=Host:api.localhost&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>        canary_tags <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;traefik.enable=false&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        check {
</span></span><span style="display:flex;"><span>          type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http&#34;</span>
</span></span><span style="display:flex;"><span>          path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>          interval <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;5s&#34;</span>
</span></span><span style="display:flex;"><span>          timeout <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1s&#34;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="testing">Testing</h2>
<p>First, we will change the <code>VERSION</code> environment variable so that Nomad sees the job as changed, and we get a different response from HTTP calls to the canary:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span>env {
</span></span><span style="display:flex;"><span><span style="color:#f92672">-  VERSION = &#34;1.0.0&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672"></span><span style="color:#a6e22e">+  VERSION = &#34;2.0.0&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e"></span>}
</span></span></code></pre></div><p>Now we will update the job in Nomad:</p>
<pre tabindex="0"><code>nomad job run jobs/echo.nomad
</code></pre><p>If we run the status command, we can see that the deployment has started, and there is one canary instance running.  Nothing further will happen until we promote it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ nomad status echo
</span></span><span style="display:flex;"><span>ID            <span style="color:#f92672">=</span> echo
</span></span><span style="display:flex;"><span>Status        <span style="color:#f92672">=</span> running
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Latest Deployment
</span></span><span style="display:flex;"><span>ID          <span style="color:#f92672">=</span> 330216b9
</span></span><span style="display:flex;"><span>Status      <span style="color:#f92672">=</span> running
</span></span><span style="display:flex;"><span>Description <span style="color:#f92672">=</span> Deployment is running but requires promotion
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Deployed
</span></span><span style="display:flex;"><span>Task Group  Promoted  Desired  Canaries  Placed  Healthy  Unhealthy  Progress Deadline
</span></span><span style="display:flex;"><span>apis        false     <span style="color:#ae81ff">3</span>        <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>        <span style="color:#ae81ff">0</span>          2019-06-19T11:19:31Z
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Allocations
</span></span><span style="display:flex;"><span>ID        Node ID   Task Group  Version  Desired  Status   Created    Modified
</span></span><span style="display:flex;"><span>dcff2555  82f6ea8b  apis        <span style="color:#ae81ff">1</span>        run      running  18s ago    2s ago
</span></span><span style="display:flex;"><span>5b2710ed  82f6ea8b  apis        <span style="color:#ae81ff">0</span>        run      running  6m52s ago  6m26s ago
</span></span><span style="display:flex;"><span>698bd8a7  82f6ea8b  apis        <span style="color:#ae81ff">0</span>        run      running  6m52s ago  6m27s ago
</span></span><span style="display:flex;"><span>b315bcd3  82f6ea8b  apis        <span style="color:#ae81ff">0</span>        run      running  6m52s ago  6m25s ago
</span></span></code></pre></div><p>We can now test that the original containers still work, and that the canary version works:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ curl http://traefik.service.consul:8080 -H <span style="color:#e6db74">&#39;Host: api.localhost&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Host: 1ac8a49cbaee, Version: 1.0.0</span>
</span></span><span style="display:flex;"><span>$ curl http://traefik.service.consul:8080 -H <span style="color:#e6db74">&#39;Host: api.localhost&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Host: 23351e48dc98, Version: 1.0.0</span>
</span></span><span style="display:flex;"><span>$ curl http://traefik.service.consul:8080 -H <span style="color:#e6db74">&#39;Host: api.localhost&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Host: c2f8a9dcab95, Version: 1.0.0</span>
</span></span><span style="display:flex;"><span>$ curl http://traefik.service.consul:8080 -H <span style="color:#e6db74">&#39;Host: api.localhost&#39;</span> -H <span style="color:#e6db74">&#39;Canary: true&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Host: 496840b438f2, Version: 2.0.0</span>
</span></span></code></pre></div><p>Assuming we are happy with our new version, we can tell Nomad to promote the deployment, which will remove the canary and start a rolling update of the three tasks, one at a time:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad deployment promote 330216b9
</span></span></code></pre></div><h2 id="end">End</h2>
<p>My hope is that the next version of Traefik will have better support for canary by header, meaning I could simplify the Nomad jobs a little, but as it stands, this doesn&rsquo;t add much complexity to the jobs, and can be easily put into an Architecture Decision Record (or documented in a wiki page, never to be seen or read from again!)</p>
]]></content:encoded></item><item><title>Running a Secure RabbitMQ Cluster in Nomad</title><link>https://andydote.co.uk/2019/04/06/nomad-rabbitmq-secure/</link><pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate><guid>https://andydote.co.uk/2019/04/06/nomad-rabbitmq-secure/</guid><description>Last time I wrote about running a RabbitMQ cluster in Nomad, one of the main pieces of feedback I received was about the (lack) of security of the setup, so I decided to revisit this, and write about how to launch as secure RabbitMQ node in Nomad.
The things I want to cover are:
Username and Password for the management UI Secure value for the Erlang Cookie SSL for Management and AMQP As usual, the demo repository with all the code is available if you&amp;rsquo;d rather just jump into that.</description><content:encoded><![CDATA[<p>Last time I wrote about running a RabbitMQ cluster in Nomad, one of the main pieces of feedback I received was about the (lack) of security of the setup, so I decided to revisit this, and write about how to launch as secure RabbitMQ node in Nomad.</p>
<p>The things I want to cover are:</p>
<ul>
<li>Username and Password for the management UI</li>
<li>Secure value for the Erlang Cookie</li>
<li>SSL for Management and AMQP</li>
</ul>
<p>As usual, the <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo">demo repository</a> with all the code is available if you&rsquo;d rather just jump into that.</p>
<h2 id="configure-nomad-to-integrate-with-vault">Configure Nomad To Integrate With Vault</h2>
<p>To manage the certificates and credentials I will use another Hashicorp tool called <a href="https://vaultproject.io/">Vault</a>, which provides Secrets As A Service.  It can be configured for High Availability, but for the demo, we will just use a single instance on one of our Nomad machines.</p>
<h3 id="vault">Vault</h3>
<p>We&rsquo;ll update the Vagrant script used in the <a href="/2019/01/28/nomad-rabbitmq-consul-cluster/">last post about Nomad Rabbitmq Clustering</a> to add in a single Vault node.  <strong>This is not suitable for using Vault in production;</strong> for that there should be a separate Vault cluster running somewhere, but as this post is focusing on how to integrate with Vault, a single node will suffice.</p>
<p>Once we have Vault installed (<a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/provision.sh#L50">see the <code>provision.sh</code> script</a>), we need to set up a few parts.  First is a PKI (public key infrastructure), better known as a Certificate Authority (CA).  We will generate a single root certificate and have our client machines (and optionally the host machine) trust that one certificate.</p>
<p>As this the machines are running in Hyper-V with the Default Switch, we can use the inbuilt domain name, <code>mshome.net</code>, and provide our own certificates.  This script is run as part of the Server (<code>nomad1</code>) provisioning script, but in a production environment would be outside of this scope.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>domain<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;mshome.net&#34;</span>
</span></span><span style="display:flex;"><span>vault secrets enable pki
</span></span><span style="display:flex;"><span>vault secrets tune -max-lease-ttl<span style="color:#f92672">=</span>87600h pki
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault write -field<span style="color:#f92672">=</span>certificate pki/root/generate/internal common_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$domain<span style="color:#e6db74">&#34;</span> ttl<span style="color:#f92672">=</span>87600h <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    &gt; /vagrant/vault/mshome.crt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault write pki/config/urls <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    issuing_certificates<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$VAULT_ADDR<span style="color:#e6db74">/v1/pki/ca&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    crl_distribution_points<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$VAULT_ADDR<span style="color:#e6db74">/v1/pki/crl&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault write pki/roles/rabbit <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    allowed_domains<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$domain<span style="color:#e6db74">&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    allow_subdomains<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    generate_lease<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    max_ttl<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;720h&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo cp /vagrant/vault/mshome.crt /usr/local/share/ca-certificates/mshome.crt
</span></span><span style="display:flex;"><span>sudo update-ca-certificates
</span></span></code></pre></div><p>If you don&rsquo;t want scary screens in FireFox and Chrome, you&rsquo;ll need to install the <code>mshome.crt</code> certificate into your trust store.</p>
<p>Next up, we have some policies we need in Vault.  The first deals with what the Nomad Server(s) are allowed to do - namely to handle tokens for itself, and anything in the <code>nomad-cluster</code> role.  <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/vault/nomad-server-policy.hcl">A full commented version of this policy is available here</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;auth/token/create/nomad-cluster&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;update&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;auth/token/roles/nomad-cluster&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;read&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;auth/token/lookup-self&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;read&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;auth/token/lookup&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;update&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;auth/token/revoke-accessor&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;update&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;sys/capabilities-self&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;update&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;auth/token/renew-self&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;update&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As this policy mentions the <code>nomad-cluster</code> role a few times, let&rsquo;s have a look at that also:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;disallowed_policies&#34;</span>: <span style="color:#e6db74">&#34;nomad-server&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;explicit_max_ttl&#34;</span>: <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;nomad-cluster&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;orphan&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;period&#34;</span>: <span style="color:#ae81ff">259200</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;renewable&#34;</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>This allows a fairly long-lived token to be created, which can be renewed.  It is also limiting what the tokens are allowed to do, which can be done as either a block list (<code>disallowed_policies</code>) or an allow list (<code>allowed_policies</code>).  In this case, I am letting the Clients access any policies except the <code>nomad-server</code> policy.</p>
<p>We can install both of these into Vault:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vault policy write nomad-server /vagrant/vault/nomad-server-policy.hcl
</span></span><span style="display:flex;"><span>vault write auth/token/roles/nomad-cluster @/vagrant/vault/nomad-cluster-role.json
</span></span></code></pre></div><h3 id="nomad">Nomad</h3>
<p>Now that Vault is up and running, we should configure Nomad to talk to it.  This is done in two places - the Server configuration, and the Client configuration.</p>
<p>To configure the <strong>Nomad Server</strong>, we update it&rsquo;s configuration file to include a <code>vault</code> block, which contains a role name it will use to generate tokens (for itself and for the Nomad Clients), and an initial token.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>vault {
</span></span><span style="display:flex;"><span>    enabled <span style="color:#f92672">=</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    address <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://localhost:8200&#34;</span>
</span></span><span style="display:flex;"><span>    task_token_ttl <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1h&#34;</span>
</span></span><span style="display:flex;"><span>    create_from_role <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;nomad-cluster&#34;</span>
</span></span><span style="display:flex;"><span>    token <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;some_token_here&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The initial token is generated by the <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/server.sh"><code>./server.sh</code></a> script - how you go about doing this in production will vary greatly depending on how you are managing your machines.</p>
<p>The <strong>Nomad Clients</strong> also need the Vault integration enabling, but in their case, it only needs the location of Vault, as the Server node(s) will provide tokens for the clients to use.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>vault {
</span></span><span style="display:flex;"><span>    enabled <span style="color:#f92672">=</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    address <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://nomad1.mshome.net:8200&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="job-requirements">Job Requirements</h2>
<p>Before we go about changing the job itself, we need to write some data into Vault for the job to use:</p>
<ul>
<li>Credentials: Username and password for the RabbitMQ Management UI, and the <code>RABBITMQ_ERLANG_COOKIE</code></li>
<li>A policy for the job allowing Certificate Generation and Credentials access</li>
</ul>
<h3 id="credentials">Credentials</h3>
<p>First off, we need to create a username and password to use with the Management UI.  This can be done via the Vault CLI:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vault kv put secret/rabbit/admin <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    username<span style="color:#f92672">=</span>administrator <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    password<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>cat /proc/sys/kernel/random/uuid<span style="color:#66d9ef">)</span>
</span></span></code></pre></div><p>For the Erlang Cookie, we will also generate a Guid, but this time we will store it under a separate path in Vault so that it can be locked down separately to the admin username and password if needed:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vault kv put secret/rabbit/cookie <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    cookie<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>cat /proc/sys/kernel/random/uuid<span style="color:#66d9ef">)</span>
</span></span></code></pre></div><h3 id="job-policy">Job Policy</h3>
<p>Following the principle of <a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege">Least Privilege</a>, we will create a policy for our <code>rabbit</code> job which only allows certificates to be generated, and rabbit credentials to be read.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;pki/issue/rabbit&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span> <span style="color:#e6db74">&#34;create&#34;</span>, <span style="color:#e6db74">&#34;read&#34;</span>, <span style="color:#e6db74">&#34;update&#34;</span>, <span style="color:#e6db74">&#34;delete&#34;</span>, <span style="color:#e6db74">&#34;list&#34;</span> <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#e6db74">&#34;secret/data/rabbit/*&#34;</span> {
</span></span><span style="display:flex;"><span>  capabilities <span style="color:#f92672">=</span> <span style="color:#f92672">[</span> <span style="color:#e6db74">&#34;read&#34;</span> <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>This is written into Vault in the same way as the other policies were:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vault policy write rabbit /vagrant/vault/rabbit-policy.hcl
</span></span></code></pre></div><h2 id="rabbit-job-configuration">Rabbit Job Configuration</h2>
<p>The first thing we need to do to the job is specify what policies we want to use with Vault, and what to do when a token or credential expires:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>task <span style="color:#e6db74">&#34;rabbit&#34;</span> {
</span></span><span style="display:flex;"><span>  driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  vault {
</span></span><span style="display:flex;"><span>    policies <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;default&#34;</span>, <span style="color:#e6db74">&#34;rabbit&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    change_mode <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;restart&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#...</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="certificates">Certificates</h3>
<p>To configure RabbitMQ to use SSL, we need to provide it with values for 3 environment variables:</p>
<ul>
<li><code>RABBITMQ_SSL_CACERTFILE</code> - The CA certificate</li>
<li><code>RABBITMQ_SSL_CERTFILE</code> - The Certificate for RabbitMQ to use</li>
<li><code>RABBITMQ_SSL_KEYFILE</code> - the PrivateKey for the RabbitMQ certificate</li>
</ul>
<p>So let&rsquo;s add a <code>template</code> block to the job to generate and write out a certificate.  It&rsquo;s worth noting that <strong>line endings matter</strong>.  You either need your <code>.nomad</code> file to use LF line endings, or make the <code>template</code> a single line and use <code>\n</code> to add the correct line endings in.  I prefer to have the file with LF line endings.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>template <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  data <span style="color:#f92672">=</span> <span style="color:#e6db74">&lt;&lt;EOH
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">{{ $host := printf &#34;common_name=%s.mshome.net&#34; (env &#34;attr.unique.hostname&#34;) }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">{{ with secret &#34;pki/issue/rabbit&#34; $host &#34;format=pem&#34; }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">{{ .Data.certificate }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">{{ .Data.private_key }}{{ end }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOH</span>
</span></span><span style="display:flex;"><span>  destination <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;secrets/rabbit.pem&#34;</span>
</span></span><span style="display:flex;"><span>  change_mode <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;restart&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>As we want to use the Nomad node&rsquo;s hostname within the <code>common_name</code> parameter of the secret, we need to use a variable to fetch and format the value:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>{{ $host :<span style="color:#f92672">=</span> printf <span style="color:#e6db74">&#34;common_name=%s.mshome.net&#34;</span> (env <span style="color:#e6db74">&#34;attr.unique.hostname&#34;</span>) }}
</span></span></code></pre></div><p>This can then be used by the <code>with secret</code> block to fetch a certificate for the current host:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>{{ with secret <span style="color:#e6db74">&#34;pki/issue/rabbit&#34;</span> $host <span style="color:#e6db74">&#34;format=pem&#34;</span> }}
</span></span></code></pre></div><p>Now that we have a certificate in the <code>./secrets/</code> directory, we can add a couple of volume mounts to the container, and set the environment variables with the container paths to the certificates.  Note how the root certificate is coming from the <code>/vagrant</code> directory, not from Vault itself.  Depending on how you are provisioning your machines to trust your CA, you will have a different path here!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>config {
</span></span><span style="display:flex;"><span>  image <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;pondidum/rabbitmq:consul&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># ...</span>
</span></span><span style="display:flex;"><span>  volumes <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;/vagrant/vault/mshome.crt:/etc/ssl/certs/mshome.crt&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;secrets/rabbit.pem:/etc/ssl/certs/rabbit.pem&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;secrets/rabbit.pem:/tmp/rabbitmq-ssl/combined.pem&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>env {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">RABBITMQ_SSL_CACERTFILE</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/etc/ssl/certs/mshome.crt&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">RABBITMQ_SSL_CERTFILE</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/etc/ssl/certs/rabbit.pem&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">RABBITMQ_SSL_KEYFILE</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/etc/ssl/certs/rabbit.pem&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#...</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>You should also notice that we are writing the <code>secrets/rabbit.pem</code> file into the container twice:  The second write is to a file in <code>/tmp</code> as a workaround for the <code>docker-entrypoint.sh</code> script.  If we don&rsquo;t create this file ourselves, the container script will create it by combining the <code>RABBITMQ_SSL_CERTFILE</code> file and <code>RABBITMQ_SSL_KEYFILE</code> file, which will result in an invalid certificate, and a nightmare to figure out&hellip;</p>
<p>If the Vault integration in Nomad could write a single generated secret to two separate files, we wouldn&rsquo;t need this workaround.  Alternatively, you could make a custom container with a customised startup script to deal with this for you.</p>
<p>You can see the version of this file with <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/a588d7c2483c999b2fa0f47433403dfe1838fd50/rabbit/secure.nomad">only these changes here</a></p>
<h3 id="credentials-1">Credentials</h3>
<p>Now that we have things running with a certificate, it would be a great idea to start using the Erlang Cookie value and Management UI credentials we stored in Vault earlier.  This is a super easy change to support in the Nomad file - we need to add another <code>template</code> block, but this time set <code>env = true</code> which will instruct nomad that the key-values in the template should be loaded as environment variables:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>template <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> <span style="color:#e6db74">&lt;&lt;EOH
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {{ with secret &#34;secret/data/rabbit/cookie&#34; }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    RABBITMQ_ERLANG_COOKIE=&#34;{{ .Data.data.cookie }}&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {{ end }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {{ with secret &#34;secret/data/rabbit/admin&#34; }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    RABBITMQ_DEFAULT_USER={{ .Data.data.username }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    RABBITMQ_DEFAULT_PASS={{ .Data.data.password }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {{ end }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOH</span>
</span></span><span style="display:flex;"><span>    destination <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;secrets/rabbit.env&#34;</span>
</span></span><span style="display:flex;"><span>    env <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>The complete nomad file with <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/a78736cac3a93a43a96cbe84492089fca29d15e1/rabbit/secure.nomad">both certificates and credentials can be seen here</a>.</p>
<h2 id="running">Running!</h2>
<p>Now, all we need to do is start our new secure cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad job run rabbit/secure.nomad
</span></span></code></pre></div><h2 id="client-libraries">Client Libraries</h2>
<p>Now that you have a secure version of RabbitMQ running, there are some interesting things which can be done with the client libraries.  While you can just use the secure port, RabbitMQ also supports <a href="https://www.rabbitmq.com/ssl.html#peer-verification">Peer Verification</a>, which means that the client has to present a certificate for itself, and RabbitMQ will validate that both certificates are signed by a common CA.</p>
<p>This process can be controlled with two environment variables:</p>
<ul>
<li><code>RABBITMQ_SSL_VERIFY</code> set to either <code>verify_peer</code> or <code>verify_none</code></li>
<li><code>RABBITMQ_SSL_FAIL_IF_NO_PEER_CERT</code> set to <code>true</code> to require client certificates, <code>false</code> to make them optional</li>
</ul>
<p>In .net land, if you are using MassTransit, the configuration looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-csharp" data-lang="csharp"><span style="display:flex;"><span><span style="color:#66d9ef">var</span> bus = Bus.Factory.CreateUsingRabbitMq(c =&gt;
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    c.UseSerilog(logger);
</span></span><span style="display:flex;"><span>    c.Host(<span style="color:#e6db74">&#34;rabbitmq://nomad1.mshome.net:5671&#34;</span>, r =&gt;
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        r.Username(<span style="color:#e6db74">&#34;some_application&#34;</span>);
</span></span><span style="display:flex;"><span>        r.Password(<span style="color:#e6db74">&#34;some_password&#34;</span>);
</span></span><span style="display:flex;"><span>        r.UseSsl(ssl =&gt;
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            ssl.CertificatePath = <span style="color:#e6db74">@&#34;secrets/app.crt&#34;</span>;
</span></span><span style="display:flex;"><span>        });
</span></span><span style="display:flex;"><span>    });
</span></span><span style="display:flex;"><span>});
</span></span></code></pre></div><p>There are also lots of other interesting things you can do with SSL and RabbitMQ, such as using the certificate as authentication rather than needing a username and password per app.  But you should be generating your app credentials dynamically with Vault too&hellip;</p>
<h1 id="wrapping-up">Wrapping Up</h1>
<p>Finding all the small parts to make this work was quite a challenge.  The <a href="https://gitter.im/hashicorp-nomad/Lobby">Nomad gitter</a> was useful when trying to figure out the certificates issue, and being able to read the <a href="https://github.com/docker-library/rabbitmq/blob/4b2b11c59ee65c2a09616b163d4572559a86bb7b/3.7/alpine/docker-entrypoint.sh#L363">source code</a> of the Docker image for RabbitMQ was invaluable to making the Certificate work.</p>
<p>If anyone sees anything I&rsquo;ve done wrong, or could be improved, I&rsquo;m happy to hear it!</p>
]]></content:encoded></item><item><title>RabbitMQ clustering with Consul in Nomad</title><link>https://andydote.co.uk/2019/01/28/nomad-rabbitmq-consul-cluster/</link><pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate><guid>https://andydote.co.uk/2019/01/28/nomad-rabbitmq-consul-cluster/</guid><description>Update If you want a secure version of this cluster, see Running a Secure RabbitMQ Cluster in Nomad.
RabbitMQ is the centre of a lot of micros service architectures, and while you can cluster it manually, it is a lot easier to use some of the auto clustering plugins, such as AWS (EC2), Consul, Etcd, or Kubernetes. As I like to use Nomad for container orchestration, I thought it would be a good idea to show how to cluster RabbitMQ when it is running in a Docker container, on an unknown host (i.</description><content:encoded><![CDATA[<p><strong>Update</strong> If you want a secure version of this cluster, see <a href="/2019/04/06/nomad-rabbitmq-secure/">Running a Secure RabbitMQ Cluster in Nomad</a>.</p>
<p>RabbitMQ is the centre of a lot of micros service architectures, and while you can cluster it manually, it is a lot easier to use some of the <a href="https://www.rabbitmq.com/clustering.html#cluster-formation-options">auto clustering plugins</a>, such as AWS (EC2), Consul, Etcd, or Kubernetes. As I like to use <a href="https://www.nomadproject.io/">Nomad</a> for container orchestration, I thought it would be a good idea to show how to cluster RabbitMQ when it is running in a Docker container, on an unknown host (i.e. one picked by Nomad.)</p>
<p>I ran into a few problems trying to get this working, but a lot of searching and some help from the <a href="https://groups.google.com/forum/#!forum/rabbitmq-users">RabbitMQ mailing list</a> (thanks Luke!) got me through all the issues, so hopefully, this will be easier next time and for other people too.</p>
<p>It is also worth noting that this is only going to be covering how to make a cluster work, not how to make it secure (setting up TLS etc.) for production usage.  There is a lot of <a href="https://www.rabbitmq.com/production-checklist.html#security-considerations">documentation on the RabbitMQ website</a> for further reading on this!</p>
<p>The full repository with all of the <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo">demo code is available on my Github</a>.</p>
<h2 id="nomad-cluster">Nomad Cluster</h2>
<p>As this post is mostly about running RabbitMQ on Nomad, and not setting up Nomad, I&rsquo;ll give the basics here - the full scripts are in the repository, and linked below too.</p>
<p>Vagrant is used to create us a three node cluster.  As I use Hyper-V for VMs, I can&rsquo;t set static IPs from the Vagrant file, so I have used another Vagrant feature: triggers.</p>
<p>Triggers let us specify scripts to run after Vagrant actions, so in this case, we run a script after machine1 comes up which writes out it&rsquo;s IP to the <code>/vagrant</code> share.  The other machines can then read this same file to join the cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span><span style="color:#66d9ef">Vagrant</span><span style="color:#f92672">.</span>configure(<span style="color:#ae81ff">2</span>) <span style="color:#66d9ef">do</span> <span style="color:#f92672">|</span>config<span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span>  config<span style="color:#f92672">.</span>vm<span style="color:#f92672">.</span>box <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;bento/ubuntu-16.04&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  config<span style="color:#f92672">.</span>vm<span style="color:#f92672">.</span>provision <span style="color:#e6db74">&#34;shell&#34;</span>, <span style="color:#e6db74">path</span>: <span style="color:#e6db74">&#34;./provision.sh&#34;</span>, <span style="color:#e6db74">privileged</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  config<span style="color:#f92672">.</span>vm<span style="color:#f92672">.</span>define <span style="color:#e6db74">&#34;n1&#34;</span> <span style="color:#66d9ef">do</span> <span style="color:#f92672">|</span>n1<span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span>    n1<span style="color:#f92672">.</span>vm<span style="color:#f92672">.</span>provision <span style="color:#e6db74">&#34;shell&#34;</span>, <span style="color:#e6db74">path</span>: <span style="color:#e6db74">&#34;./server.sh&#34;</span>, <span style="color:#e6db74">privileged</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    n1<span style="color:#f92672">.</span>trigger<span style="color:#f92672">.</span>after <span style="color:#e6db74">:up</span> <span style="color:#66d9ef">do</span> <span style="color:#f92672">|</span>trigger<span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span>      trigger<span style="color:#f92672">.</span>run_remote <span style="color:#f92672">=</span> { <span style="color:#e6db74">inline</span>: <span style="color:#e6db74">&#34;ip route get 1 | awk &#39;{print $NF;exit}&#39; &gt; /vagrant/server_ip&#34;</span> }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">end</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">end</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  config<span style="color:#f92672">.</span>vm<span style="color:#f92672">.</span>define <span style="color:#e6db74">&#34;n2&#34;</span> <span style="color:#66d9ef">do</span> <span style="color:#f92672">|</span>n2<span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span>    n2<span style="color:#f92672">.</span>vm<span style="color:#f92672">.</span>hostname <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;nomad2&#34;</span>
</span></span><span style="display:flex;"><span>    n2<span style="color:#f92672">.</span>vm<span style="color:#f92672">.</span>provision <span style="color:#e6db74">&#34;shell&#34;</span>, <span style="color:#e6db74">path</span>: <span style="color:#e6db74">&#34;./client.sh&#34;</span>, <span style="color:#e6db74">privileged</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">end</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span>
</span></span></code></pre></div><p>The <code>provision.sh</code> script downloads and installs both Consul and Nomad, and then the respective <code>server.sh</code> and <code>client.sh</code> scripts set up both services in the right ways.  The server machine also acts as a Nomad client, so that we don&rsquo;t need 4 VMs running.</p>
<p><a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/vagrantfile">VagrantFile</a>, <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/provision.sh">provision.sh</a>, <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/server.sh">server.sh</a>, <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/client.sh">client.sh</a></p>
<p>All that remains to be done is <code>vagrant up</code>&hellip;and wait.  But while we&rsquo;re waiting for the machines to provision, let&rsquo;s have a look at RabbitMQ clustering, and how we&rsquo;ll define the job in Nomad.</p>
<h2 id="rabbitmq-cluster">RabbitMQ Cluster</h2>
<p>A few things to note about clustering RabbitMQ:</p>
<ul>
<li>All nodes must be listening on the same port for clustering (<code>4369</code> by default)</li>
<li>The <code>ERL_EPMD_PORT</code> variable doesn&rsquo;t work on <code>rabbitmq &lt; 3.7.9</code></li>
<li>The latest Docker image for rabbitmq is <code>3.7.8</code></li>
<li>The rabbit node names must be DNS resolvable</li>
<li>The <code>RABBITMQ_ERLANG_COOKIE</code> must have the same value</li>
</ul>
<p>The <code>rabbitmq_peer_discovery_consul</code> plugin we will use is shipped with RabbitMQ by default but is disabled.  The easiest way to get everything up and running is to create your own docker container, with the plugin enabled, and a small configuration file to set a few options:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-conf" data-lang="conf"><span style="display:flex;"><span>FROM rabbitmq<span style="color:#960050;background-color:#1e0010">:</span>management-alpine
</span></span><span style="display:flex;"><span>COPY rabbitmq.conf <span style="color:#960050;background-color:#1e0010">/</span>etc<span style="color:#960050;background-color:#1e0010">/</span>rabbitmq
</span></span><span style="display:flex;"><span>RUN rabbitmq-plugins enable --offline rabbitmq_peer_discovery_consul
</span></span></code></pre></div><p>The <code>rabbitmq.conf</code> only needs a few lines:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-conf" data-lang="conf"><span style="display:flex;"><span>cluster_formation.peer_discovery_backend <span style="color:#f92672">=</span> rabbit_peer_discovery_consul
</span></span><span style="display:flex;"><span>cluster_formation.consul.svc_addr_auto <span style="color:#f92672">=</span> <span style="color:#66d9ef">true</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker build -t rabbitmq:consul .
</span></span></code></pre></div><p>An image built from this is also available on <a href="https://hub.docker.com/r/pondidum/rabbitmq">docker hub</a>.</p>
<p>Once we have a custom container built, it&rsquo;s a good idea to test that it actually works, before we start trying to get Nomad to run it.  We&rsquo;ll do this by creating a network in Docker so that all the containers can talk directly to each other on their pre-defined ports.  Don&rsquo;t forget to change <code>CONSUL_HOST</code> to your machine&rsquo;s IP address!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker network create rabbit
</span></span><span style="display:flex;"><span>docker run -d --rm --name consul -p 8500:8500 consul
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>docker run -d --rm --name rabbit1 -h rabbit1 --network rabbit -p 30001:15672 -e RABBITMQ_ERLANG_COOKIE<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rabbit&#39;</span> -e <span style="color:#e6db74">&#39;RABBITMQ_DEFAULT_USER=test&#39;</span> -e <span style="color:#e6db74">&#39;RABBITMQ_DEFAULT_PASS=test&#39;</span> -e CONSUL_HOST<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;10.0.75.1&#39;</span> rabbitmq:consul
</span></span><span style="display:flex;"><span>docker run -d --rm --name rabbit2 -h rabbit2 --network rabbit -p 30002:15672 -e RABBITMQ_ERLANG_COOKIE<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rabbit&#39;</span> -e <span style="color:#e6db74">&#39;RABBITMQ_DEFAULT_USER=test&#39;</span> -e <span style="color:#e6db74">&#39;RABBITMQ_DEFAULT_PASS=test&#39;</span> -e CONSUL_HOST<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;10.0.75.1&#39;</span> rabbitmq:consul
</span></span><span style="display:flex;"><span>docker run -d --rm --name rabbit3 -h rabbit3 --network rabbit -p 30003:15672 -e RABBITMQ_ERLANG_COOKIE<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rabbit&#39;</span> -e <span style="color:#e6db74">&#39;RABBITMQ_DEFAULT_USER=test&#39;</span> -e <span style="color:#e6db74">&#39;RABBITMQ_DEFAULT_PASS=test&#39;</span> -e CONSUL_HOST<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;10.0.75.1&#39;</span> rabbitmq:consul
</span></span></code></pre></div><p>You can now visit <code>http://localhost:30001</code> (or <code>30002</code> or <code>30003</code>) and see that we have a successful cluster running.  Once you&rsquo;re happy with it, you can kill it all off (as we started the containers with the <code>--rm</code> flag, Docker will delete them for us when they stop):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker stop rabbit1 rabbit2 rabbit3 consul
</span></span><span style="display:flex;"><span>docker network rm rabbit
</span></span></code></pre></div><h2 id="nomad-rabbit-job">Nomad Rabbit Job</h2>
<p>Now that we know our container clusters successfully, we can create a Job definition to do the same thing in Nomad.  Nomad jobs are defined in HCL, a Json-like configuration language.</p>
<p>The jobs require a name, which datacentre it should run in, and what kind of job type it is.  In this case, our job is called <code>rabbit</code> (imaginative I know), we&rsquo;ll run it in <code>dc1</code> (the default value Nomad starts with), and we&rsquo;ll make this job be a <code>service</code>, as opposed to a <code>batch</code> or <code>system</code> job:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>job <span style="color:#e6db74">&#34;rabbit&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  datacenters <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;dc1&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;service&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  group <span style="color:#e6db74">&#34;cluster&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># tasks ...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>The <code>group</code> is used to hold a collection of <code>task</code>s, and when allocating a job, Nomad will make sure that all tasks belonging to an instance of a group are on the same node.</p>
<p>So for example, if you had a 2 node Nomad cluster, and 3 instances of a group which contained 3 tasks (e.g. API, varnish, and nginx containers), Nomad might distribute the groups like so:</p>
<p><img loading="lazy" src="nomad-allocation.png" alt="image of several nodes with groups of containers"  />
</p>
<p>Within the group, we can specify the number of instances we want with the <code>count</code> property, and we also specify that for both updates and migrations, only one group can be changed at a time.  This means that if you decide to upgrade the container used by the job, Nomad won&rsquo;t stop all instances at once, destroying your service&rsquo;s availability!</p>
<p>We also specify that we want to use the health checks (defined later on) rather than the state of the task itself to determine what is healthy, and how long the task must be healthy for before we decide it&rsquo;s actually healthy, and how long it has to achieve being healthy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>group <span style="color:#e6db74">&#34;cluster&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  count <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  update <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    max_parallel <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  migrate <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    max_parallel <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    health_check <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;checks&#34;</span>
</span></span><span style="display:flex;"><span>    min_healthy_time <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;5s&#34;</span>
</span></span><span style="display:flex;"><span>    healthy_deadline <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;30s&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>The <code>task</code> is our unit of work in Nomad.  In this case, we are using the <code>docker</code> driver, but it also <a href="https://www.nomadproject.io/docs/drivers/index.html">supports many other drivers</a> including <code>exec</code>, <code>rkt</code> and <code>lxc</code>.  We configure which image to use, and importantly that the <code>hostname</code> is the name from Nomad!</p>
<p>The <code>port_map</code> tells nomad which ports of the container we want to expose, and labels them.  We can then refer to the ports by their labels in other parts of the configuration.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>task <span style="color:#e6db74">&#34;rabbit&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  config <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    image <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;pondidum/rabbitmq:consul&#34;</span>
</span></span><span style="display:flex;"><span>    hostname <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>attr.unique.hostname<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    port_map <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      amqp <span style="color:#f92672">=</span> <span style="color:#ae81ff">5672</span>
</span></span><span style="display:flex;"><span>      ui <span style="color:#f92672">=</span> <span style="color:#ae81ff">15672</span>
</span></span><span style="display:flex;"><span>      epmd <span style="color:#f92672">=</span> <span style="color:#ae81ff">4369</span>
</span></span><span style="display:flex;"><span>      clustering <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>The <code>env</code> section is pretty self-explanatory; they are environment variables to pass to the container.  As Consul is running on the Nomad host, we use the Nomad interpolation attribute to specify the IP of the current host, and we also set the <code>RABBITMQ_ERLANG_COOKIE</code> to a specific value.  In a production environment, you should be setting this value to something unguessable, possibly using the <a href="https://www.nomadproject.io/docs/job-specification/vault.html">Vault intergration</a> in Nomad to fetch a token.  We can also add other settings to pass to the container here, such as <code>RABBITMQ_DEFAULT_USER</code> and <code>RABBITMQ_DEFAULT_PASS</code>.  As with the cookie generation, in a production-like environment, you&rsquo;d probably want to use the Vault integration to pull the values for these variables.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>env <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  RABBITMQ_ERLANG_COOKIE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;rabbitmq&#34;</span>
</span></span><span style="display:flex;"><span>  CONSUL_HOST <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>attr.unique.network.ip-address<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>The <code>resources</code> section lets us constraints on things like CPU, Memory, IOPs, and Network.  In our case, we are only specifying a set of ports to expose on the network, and that we want them to be bound to specific ports on the host:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>resources <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  network <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    port <span style="color:#e6db74">&#34;amqp&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">5672</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    port <span style="color:#e6db74">&#34;ui&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">15672</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    port <span style="color:#e6db74">&#34;epmd&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">4369</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    port <span style="color:#e6db74">&#34;clustering&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">25672</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>We could select different ports to bind the container ports to, or leave out the <code>static</code> pair entirely to have Nomad map the ports to random unused ports on the host.</p>
<p>Finally, the <code>service</code> block integrates with service discovery (so, Consul), and allows us to register ports and health checks for our service.  In the case of our RabbitMQ cluster, we already have service discovery integration via the RabbitMQ Consul plugin, so this registration is only used for the <code>check</code> feature, which is what will also be used by the <code>migrate</code> block to see if a task is healthy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>service <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  check <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    name     <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;alive&#34;</span>
</span></span><span style="display:flex;"><span>    type     <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;tcp&#34;</span>
</span></span><span style="display:flex;"><span>    port     <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ui&#34;</span>
</span></span><span style="display:flex;"><span>    interval <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;10s&#34;</span>
</span></span><span style="display:flex;"><span>    timeout  <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;2s&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>The check is using the <code>ui</code> port defined earlier to check if the UI is alive.  We could also change the health check to use the <code>amqp</code> port instead, as that might be a better indication that the actual service can do useful things.  We can define multiple checks, and are not limited to TCP; <code>grpc</code>, <code>http</code>, and <code>script</code> are also supported.</p>
<p>The entire job definition is below, and is <a href="https://github.com/Pondidum/Nomad-RabbitMQ-Demo/blob/master/rabbit/rabbit.nomad">also available in the repository</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>job <span style="color:#e6db74">&#34;rabbit&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  datacenters <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;dc1&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;service&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  group <span style="color:#e6db74">&#34;cluster&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    update <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      max_parallel <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    migrate <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      max_parallel <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>      health_check <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;checks&#34;</span>
</span></span><span style="display:flex;"><span>      min_healthy_time <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;5s&#34;</span>
</span></span><span style="display:flex;"><span>      healthy_deadline <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;30s&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    task <span style="color:#e6db74">&#34;rabbit&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;docker&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      config <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        image <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;pondidum/rabbitmq:consul&#34;</span>
</span></span><span style="display:flex;"><span>        hostname <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>attr.unique.hostname<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        port_map <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>          amqp <span style="color:#f92672">=</span> <span style="color:#ae81ff">5672</span>
</span></span><span style="display:flex;"><span>          ui <span style="color:#f92672">=</span> <span style="color:#ae81ff">15672</span>
</span></span><span style="display:flex;"><span>          epmd <span style="color:#f92672">=</span> <span style="color:#ae81ff">4369</span>
</span></span><span style="display:flex;"><span>          clustering <span style="color:#f92672">=</span> <span style="color:#ae81ff">25672</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      env <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        RABBITMQ_ERLANG_COOKIE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;generate_a_guid_-_or_something_for_this&#34;</span>
</span></span><span style="display:flex;"><span>        RABBITMQ_DEFAULT_USER <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;test&#34;</span>
</span></span><span style="display:flex;"><span>        RABBITMQ_DEFAULT_PASS <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;test&#34;</span>
</span></span><span style="display:flex;"><span>        CONSUL_HOST <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>attr.unique.network.ip-address<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      resources <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        network <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;amqp&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">5672</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;ui&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">15672</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;epmd&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">4369</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>          port <span style="color:#e6db74">&#34;clustering&#34;</span> <span style="color:#f92672">{</span> static <span style="color:#f92672">=</span> <span style="color:#ae81ff">25672</span> <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      service <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;rabbitmq&#34;</span>
</span></span><span style="display:flex;"><span>        port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ui&#34;</span>
</span></span><span style="display:flex;"><span>        check <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>          name     <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;alive&#34;</span>
</span></span><span style="display:flex;"><span>          type     <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;tcp&#34;</span>
</span></span><span style="display:flex;"><span>          interval <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;10s&#34;</span>
</span></span><span style="display:flex;"><span>          timeout  <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;2s&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><h2 id="running-the-job">Running The Job</h2>
<p>First, make sure your console can talk to Nomad, which we can do by using the <code>server_ip</code> file again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export NOMAD_ADDR<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://</span><span style="color:#66d9ef">$(</span>cat server_ip<span style="color:#66d9ef">)</span><span style="color:#e6db74">:4646&#34;</span>
</span></span></code></pre></div><p>Now it should be possible to run the job:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nomad job run rabbit/rabbit.nomad
</span></span></code></pre></div><p>After a few moments, we can visit any of the Nomad hosts, and log in to the RabbitMQ UI (<code>http://SOME_SERVER_IP:15672</code>) and you should be greeted with a running cluster with three nodes:</p>
<p><img loading="lazy" src="rabbitmq-cluster.png" alt="rabbitmq cluster dashboard"  />
</p>
<h2 id="homework">Homework</h2>
<ul>
<li>Kill a container on one of the nodes and see what happens (<code>vagrant ssh n2</code> then <code>docker stop &lt;SOME_CONTAINER_ID&gt;</code>)</li>
<li>Create an Application which you deploy to Nomad which uses service discovery to talk to RabbitMQ</li>
<li>Create some more Nomad clients, and try making a bigger RabbitMQ cluster</li>
</ul>
<p>If you have any questions, feel free to comment below or <a href="https://twitter.com/pondidum">send me a tweet</a>.</p>
]]></content:encoded></item></channel></rss>